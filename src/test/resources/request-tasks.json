{
  "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1",
  "Requests" : {
    "cluster_name" : "MySingleNodeCluster",
    "id" : 1
  },
  "tasks" : [
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/2",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "DATANODE INSTALL",
        "end_time" : 1401352832117,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 2,
        "request_id" : 1,
        "role" : "DATANODE",
        "stage_id" : 1,
        "start_time" : 1401352497755,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:35:03,823 - Group['hadoop'] {}\n2014-05-29 04:35:03,826 - Adding group Group['hadoop']\n2014-05-29 04:35:03,856 - Group['users'] {}\n2014-05-29 04:35:03,857 - Modifying group users\n2014-05-29 04:35:03,878 - Group['users'] {}\n2014-05-29 04:35:03,878 - Modifying group users\n2014-05-29 04:35:03,898 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:35:03,898 - Adding user User['ambari-qa']\n2014-05-29 04:35:03,942 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:35:03,947 - Writing File['/tmp/changeUid.sh'] because it doesn't exist\n2014-05-29 04:35:03,947 - Changing permission for /tmp/changeUid.sh from 644 to 555\n2014-05-29 04:35:03,948 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:35:03,998 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:35:03,999 - Adding user User['yarn']\n2014-05-29 04:35:04,025 - Group['nobody'] {}\n2014-05-29 04:35:04,025 - Modifying group nobody\n2014-05-29 04:35:04,046 - Group['nobody'] {}\n2014-05-29 04:35:04,047 - Modifying group nobody\n2014-05-29 04:35:04,066 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:35:04,067 - Modifying user nobody\n2014-05-29 04:35:04,093 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:35:04,093 - Modifying user nobody\n2014-05-29 04:35:04,110 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:35:04,111 - Adding user User['hdfs']\n2014-05-29 04:35:04,145 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:35:04,146 - Adding user User['mapred']\n2014-05-29 04:35:04,182 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:35:04,182 - Adding user User['zookeeper']\n2014-05-29 04:35:04,211 - Package['unzip'] {}\n2014-05-29 04:35:04,236 - Installing package unzip ('/usr/bin/yum -d 0 -e 0 -y install unzip')\n2014-05-29 04:35:05,223 - Package['net-snmp'] {}\n2014-05-29 04:35:05,241 - Installing package net-snmp ('/usr/bin/yum -d 0 -e 0 -y install net-snmp')\n2014-05-29 04:35:26,033 - Package['net-snmp-utils'] {}\n2014-05-29 04:35:26,055 - Installing package net-snmp-utils ('/usr/bin/yum -d 0 -e 0 -y install net-snmp-utils')\n2014-05-29 04:35:27,632 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:35:27,640 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:35:27,641 - Writing File['/etc/yum.repos.d/HDP.repo'] because it doesn't exist\n2014-05-29 04:35:27,642 - Package['lzo'] {}\n2014-05-29 04:35:27,659 - Installing package lzo ('/usr/bin/yum -d 0 -e 0 -y install lzo')\n2014-05-29 04:35:29,913 - Package['hadoop'] {}\n2014-05-29 04:35:29,930 - Installing package hadoop ('/usr/bin/yum -d 0 -e 0 -y install hadoop')\n2014-05-29 04:38:37,938 - Package['hadoop-libhdfs'] {}\n2014-05-29 04:38:37,991 - Installing package hadoop-libhdfs ('/usr/bin/yum -d 0 -e 0 -y install hadoop-libhdfs')\n2014-05-29 04:39:41,452 - Package['hadoop-lzo'] {}\n2014-05-29 04:39:41,477 - Installing package hadoop-lzo ('/usr/bin/yum -d 0 -e 0 -y install hadoop-lzo')\n2014-05-29 04:39:42,280 - Package['hadoop-lzo-native'] {}\n2014-05-29 04:39:42,303 - Installing package hadoop-lzo-native ('/usr/bin/yum -d 0 -e 0 -y install hadoop-lzo-native')\n2014-05-29 04:40:28,182 - Package['snappy'] {}\n2014-05-29 04:40:28,206 - Installing package snappy ('/usr/bin/yum -d 0 -e 0 -y install snappy')\n2014-05-29 04:40:29,327 - Package['snappy-devel'] {}\n2014-05-29 04:40:29,349 - Installing package snappy-devel ('/usr/bin/yum -d 0 -e 0 -y install snappy-devel')\n2014-05-29 04:40:30,100 - Package['ambari-log4j'] {}\n2014-05-29 04:40:30,122 - Installing package ambari-log4j ('/usr/bin/yum -d 0 -e 0 -y install ambari-log4j')",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/3",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "GANGLIA_MONITOR INSTALL",
        "end_time" : 1401352949459,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 3,
        "request_id" : 1,
        "role" : "GANGLIA_MONITOR",
        "stage_id" : 1,
        "start_time" : 1401352497827,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:40:34,304 - Group['hadoop'] {}\n2014-05-29 04:40:34,305 - Modifying group hadoop\n2014-05-29 04:40:34,332 - Group['users'] {}\n2014-05-29 04:40:34,332 - Modifying group users\n2014-05-29 04:40:34,360 - Group['users'] {}\n2014-05-29 04:40:34,360 - Modifying group users\n2014-05-29 04:40:34,385 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:40:34,386 - Modifying user ambari-qa\n2014-05-29 04:40:34,412 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:40:34,414 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:40:34,430 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:40:34,431 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:40:34,431 - Modifying user yarn\n2014-05-29 04:40:34,459 - Group['nobody'] {}\n2014-05-29 04:40:34,460 - Modifying group nobody\n2014-05-29 04:40:34,496 - Group['nobody'] {}\n2014-05-29 04:40:34,496 - Modifying group nobody\n2014-05-29 04:40:34,522 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:40:34,524 - Modifying user nobody\n2014-05-29 04:40:34,546 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:40:34,547 - Modifying user nobody\n2014-05-29 04:40:34,568 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:40:34,569 - Modifying user hdfs\n2014-05-29 04:40:34,591 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:40:34,592 - Modifying user mapred\n2014-05-29 04:40:34,611 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:40:34,612 - Modifying user zookeeper\n2014-05-29 04:40:34,632 - Package['unzip'] {}\n2014-05-29 04:40:34,656 - Skipping installing existent package unzip\n2014-05-29 04:40:34,656 - Package['net-snmp'] {}\n2014-05-29 04:40:34,680 - Skipping installing existent package net-snmp\n2014-05-29 04:40:34,680 - Package['net-snmp-utils'] {}\n2014-05-29 04:40:34,704 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:40:34,855 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:40:34,860 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:40:34,861 - Package['libganglia-3.5.0-99'] {}\n2014-05-29 04:40:34,884 - Installing package libganglia-3.5.0-99 ('/usr/bin/yum -d 0 -e 0 -y install libganglia-3.5.0-99')\n2014-05-29 04:40:36,693 - Package['ganglia-devel-3.5.0-99'] {}\n2014-05-29 04:40:36,716 - Installing package ganglia-devel-3.5.0-99 ('/usr/bin/yum -d 0 -e 0 -y install ganglia-devel-3.5.0-99')\n2014-05-29 04:40:38,206 - Package['ganglia-gmetad-3.5.0-99'] {}\n2014-05-29 04:40:38,228 - Installing package ganglia-gmetad-3.5.0-99 ('/usr/bin/yum -d 0 -e 0 -y install ganglia-gmetad-3.5.0-99')\n2014-05-29 04:40:56,458 - Package['ganglia-web-3.5.7-99.noarch'] {}\n2014-05-29 04:40:56,481 - Installing package ganglia-web-3.5.7-99.noarch ('/usr/bin/yum -d 0 -e 0 -y install ganglia-web-3.5.7-99.noarch')\n2014-05-29 04:42:25,938 - Package['python-rrdtool.x86_64'] {}\n2014-05-29 04:42:25,963 - Installing package python-rrdtool.x86_64 ('/usr/bin/yum -d 0 -e 0 -y install python-rrdtool.x86_64')\n2014-05-29 04:42:26,887 - Package['ganglia-gmond-3.5.0-99'] {}\n2014-05-29 04:42:26,910 - Installing package ganglia-gmond-3.5.0-99 ('/usr/bin/yum -d 0 -e 0 -y install ganglia-gmond-3.5.0-99')\n2014-05-29 04:42:27,726 - Package['ganglia-gmond-modules-python-3.5.0-99'] {}\n2014-05-29 04:42:27,749 - Installing package ganglia-gmond-modules-python-3.5.0-99 ('/usr/bin/yum -d 0 -e 0 -y install ganglia-gmond-modules-python-3.5.0-99')\n2014-05-29 04:42:28,605 - Package['httpd'] {}\n2014-05-29 04:42:28,630 - Skipping installing existent package httpd\n2014-05-29 04:42:28,631 - Directory['/etc/ganglia/hdp'] {'owner': 'root', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:42:28,631 - Creating directory Directory['/etc/ganglia/hdp']\n2014-05-29 04:42:28,632 - Changing group for /etc/ganglia/hdp from 0 to hadoop\n2014-05-29 04:42:28,632 - Directory['/usr/libexec/hdp/ganglia'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:42:28,632 - Creating directory Directory['/usr/libexec/hdp/ganglia']\n2014-05-29 04:42:28,633 - File['/etc/init.d/hdp-gmetad'] {'content': StaticFile('gmetad.init'), 'mode': 0755}\n2014-05-29 04:42:28,635 - Writing File['/etc/init.d/hdp-gmetad'] because it doesn't exist\n2014-05-29 04:42:28,635 - Changing permission for /etc/init.d/hdp-gmetad from 644 to 755\n2014-05-29 04:42:28,635 - File['/etc/init.d/hdp-gmond'] {'content': StaticFile('gmond.init'), 'mode': 0755}\n2014-05-29 04:42:28,636 - Writing File['/etc/init.d/hdp-gmond'] because it doesn't exist\n2014-05-29 04:42:28,636 - Changing permission for /etc/init.d/hdp-gmond from 644 to 755\n2014-05-29 04:42:28,636 - File['/usr/libexec/hdp/ganglia/checkGmond.sh'] {'content': StaticFile('checkGmond.sh'), 'mode': 0755}\n2014-05-29 04:42:28,637 - Writing File['/usr/libexec/hdp/ganglia/checkGmond.sh'] because it doesn't exist\n2014-05-29 04:42:28,638 - Changing permission for /usr/libexec/hdp/ganglia/checkGmond.sh from 644 to 755\n2014-05-29 04:42:28,638 - File['/usr/libexec/hdp/ganglia/checkRrdcached.sh'] {'content': StaticFile('checkRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:42:28,638 - Writing File['/usr/libexec/hdp/ganglia/checkRrdcached.sh'] because it doesn't exist\n2014-05-29 04:42:28,639 - Changing permission for /usr/libexec/hdp/ganglia/checkRrdcached.sh from 644 to 755\n2014-05-29 04:42:28,639 - File['/usr/libexec/hdp/ganglia/gmetadLib.sh'] {'content': StaticFile('gmetadLib.sh'), 'mode': 0755}\n2014-05-29 04:42:28,640 - Writing File['/usr/libexec/hdp/ganglia/gmetadLib.sh'] because it doesn't exist\n2014-05-29 04:42:28,640 - Changing permission for /usr/libexec/hdp/ganglia/gmetadLib.sh from 644 to 755\n2014-05-29 04:42:28,640 - File['/usr/libexec/hdp/ganglia/gmondLib.sh'] {'content': StaticFile('gmondLib.sh'), 'mode': 0755}\n2014-05-29 04:42:28,641 - Writing File['/usr/libexec/hdp/ganglia/gmondLib.sh'] because it doesn't exist\n2014-05-29 04:42:28,642 - Changing permission for /usr/libexec/hdp/ganglia/gmondLib.sh from 644 to 755\n2014-05-29 04:42:28,642 - File['/usr/libexec/hdp/ganglia/rrdcachedLib.sh'] {'content': StaticFile('rrdcachedLib.sh'), 'mode': 0755}\n2014-05-29 04:42:28,642 - Writing File['/usr/libexec/hdp/ganglia/rrdcachedLib.sh'] because it doesn't exist\n2014-05-29 04:42:28,642 - Changing permission for /usr/libexec/hdp/ganglia/rrdcachedLib.sh from 644 to 755\n2014-05-29 04:42:28,643 - File['/usr/libexec/hdp/ganglia/setupGanglia.sh'] {'content': StaticFile('setupGanglia.sh'), 'mode': 0755}\n2014-05-29 04:42:28,644 - Writing File['/usr/libexec/hdp/ganglia/setupGanglia.sh'] because it doesn't exist\n2014-05-29 04:42:28,644 - Changing permission for /usr/libexec/hdp/ganglia/setupGanglia.sh from 644 to 755\n2014-05-29 04:42:28,644 - File['/usr/libexec/hdp/ganglia/startGmetad.sh'] {'content': StaticFile('startGmetad.sh'), 'mode': 0755}\n2014-05-29 04:42:28,644 - Writing File['/usr/libexec/hdp/ganglia/startGmetad.sh'] because it doesn't exist\n2014-05-29 04:42:28,645 - Changing permission for /usr/libexec/hdp/ganglia/startGmetad.sh from 644 to 755\n2014-05-29 04:42:28,645 - File['/usr/libexec/hdp/ganglia/startGmond.sh'] {'content': StaticFile('startGmond.sh'), 'mode': 0755}\n2014-05-29 04:42:28,646 - Writing File['/usr/libexec/hdp/ganglia/startGmond.sh'] because it doesn't exist\n2014-05-29 04:42:28,646 - Changing permission for /usr/libexec/hdp/ganglia/startGmond.sh from 644 to 755\n2014-05-29 04:42:28,647 - File['/usr/libexec/hdp/ganglia/startRrdcached.sh'] {'content': StaticFile('startRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:42:28,647 - Writing File['/usr/libexec/hdp/ganglia/startRrdcached.sh'] because it doesn't exist\n2014-05-29 04:42:28,647 - Changing permission for /usr/libexec/hdp/ganglia/startRrdcached.sh from 644 to 755\n2014-05-29 04:42:28,647 - File['/usr/libexec/hdp/ganglia/stopGmetad.sh'] {'content': StaticFile('stopGmetad.sh'), 'mode': 0755}\n2014-05-29 04:42:28,648 - Writing File['/usr/libexec/hdp/ganglia/stopGmetad.sh'] because it doesn't exist\n2014-05-29 04:42:28,648 - Changing permission for /usr/libexec/hdp/ganglia/stopGmetad.sh from 644 to 755\n2014-05-29 04:42:28,648 - File['/usr/libexec/hdp/ganglia/stopGmond.sh'] {'content': StaticFile('stopGmond.sh'), 'mode': 0755}\n2014-05-29 04:42:28,649 - Writing File['/usr/libexec/hdp/ganglia/stopGmond.sh'] because it doesn't exist\n2014-05-29 04:42:28,649 - Changing permission for /usr/libexec/hdp/ganglia/stopGmond.sh from 644 to 755\n2014-05-29 04:42:28,649 - File['/usr/libexec/hdp/ganglia/stopRrdcached.sh'] {'content': StaticFile('stopRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:42:28,650 - Writing File['/usr/libexec/hdp/ganglia/stopRrdcached.sh'] because it doesn't exist\n2014-05-29 04:42:28,650 - Changing permission for /usr/libexec/hdp/ganglia/stopRrdcached.sh from 644 to 755\n2014-05-29 04:42:28,650 - File['/usr/libexec/hdp/ganglia/teardownGanglia.sh'] {'content': StaticFile('teardownGanglia.sh'), 'mode': 0755}\n2014-05-29 04:42:28,651 - Writing File['/usr/libexec/hdp/ganglia/teardownGanglia.sh'] because it doesn't exist\n2014-05-29 04:42:28,651 - Changing permission for /usr/libexec/hdp/ganglia/teardownGanglia.sh from 644 to 755\n2014-05-29 04:42:28,651 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:28,659 - File['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] {'content': Template('gangliaClusters.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:28,660 - Writing File['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] because it doesn't exist\n2014-05-29 04:42:28,660 - Changing permission for /usr/libexec/hdp/ganglia/gangliaClusters.conf from 644 to 755\n2014-05-29 04:42:28,660 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:28,663 - File['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] {'content': Template('gangliaEnv.sh.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:28,663 - Writing File['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] because it doesn't exist\n2014-05-29 04:42:28,663 - Changing permission for /usr/libexec/hdp/ganglia/gangliaEnv.sh from 644 to 755\n2014-05-29 04:42:28,664 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaLib.sh'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:28,667 - File['/usr/libexec/hdp/ganglia/gangliaLib.sh'] {'content': Template('gangliaLib.sh.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:28,668 - Writing File['/usr/libexec/hdp/ganglia/gangliaLib.sh'] because it doesn't exist\n2014-05-29 04:42:28,668 - Changing permission for /usr/libexec/hdp/ganglia/gangliaLib.sh from 644 to 755\n2014-05-29 04:42:28,668 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPNameNode -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:28,718 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPResourceManager -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:28,768 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPHistoryServer -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:28,815 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPSlaves -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:28,863 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPDataNode -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:28,910 - Directory['/etc/ganglia/conf.d'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:42:28,910 - Changing group for /etc/ganglia/conf.d from 0 to hadoop\n2014-05-29 04:42:28,910 - File['/etc/ganglia/conf.d/modgstatus.conf'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:42:28,911 - Changing group for /etc/ganglia/conf.d/modgstatus.conf from 0 to hadoop\n2014-05-29 04:42:28,911 - File['/etc/ganglia/conf.d/multicpu.conf'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:42:28,911 - Writing File['/etc/ganglia/conf.d/multicpu.conf'] because it doesn't exist\n2014-05-29 04:42:28,911 - Changing group for /etc/ganglia/conf.d/multicpu.conf from 0 to hadoop\n2014-05-29 04:42:28,911 - File['/etc/ganglia/gmond.conf'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:42:28,912 - Changing group for /etc/ganglia/gmond.conf from 0 to hadoop\n2014-05-29 04:42:28,912 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPNameNode -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:28,961 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPResourceManager -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:29,010 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPNodeManager -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:29,059 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPHistoryServer -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:29,107 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPDataNode -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:29,155 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPSlaves -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:29,202 - Execute['chkconfig gmond off'] {'path': ['/usr/sbin:/sbin:/usr/local/bin:/bin:/usr/bin']}\n2014-05-29 04:42:29,217 - Execute['chkconfig gmetad off'] {'path': ['/usr/sbin:/sbin:/usr/local/bin:/bin:/usr/bin']}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/4",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "GANGLIA_SERVER INSTALL",
        "end_time" : 1401352952077,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 4,
        "request_id" : 1,
        "role" : "GANGLIA_SERVER",
        "stage_id" : 1,
        "start_time" : 1401352497856,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:42:31,060 - Group['hadoop'] {}\n2014-05-29 04:42:31,061 - Modifying group hadoop\n2014-05-29 04:42:31,094 - Group['users'] {}\n2014-05-29 04:42:31,094 - Modifying group users\n2014-05-29 04:42:31,121 - Group['users'] {}\n2014-05-29 04:42:31,121 - Modifying group users\n2014-05-29 04:42:31,148 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:42:31,149 - Modifying user ambari-qa\n2014-05-29 04:42:31,171 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:42:31,172 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:42:31,188 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:42:31,189 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:42:31,189 - Modifying user yarn\n2014-05-29 04:42:31,210 - Group['nobody'] {}\n2014-05-29 04:42:31,211 - Modifying group nobody\n2014-05-29 04:42:31,237 - Group['nobody'] {}\n2014-05-29 04:42:31,238 - Modifying group nobody\n2014-05-29 04:42:31,264 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:42:31,264 - Modifying user nobody\n2014-05-29 04:42:31,286 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:42:31,287 - Modifying user nobody\n2014-05-29 04:42:31,309 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:42:31,310 - Modifying user hdfs\n2014-05-29 04:42:31,332 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:42:31,332 - Modifying user mapred\n2014-05-29 04:42:31,355 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:42:31,356 - Modifying user zookeeper\n2014-05-29 04:42:31,377 - Package['unzip'] {}\n2014-05-29 04:42:31,400 - Skipping installing existent package unzip\n2014-05-29 04:42:31,400 - Package['net-snmp'] {}\n2014-05-29 04:42:31,424 - Skipping installing existent package net-snmp\n2014-05-29 04:42:31,424 - Package['net-snmp-utils'] {}\n2014-05-29 04:42:31,449 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:42:31,581 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:42:31,587 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:42:31,588 - Package['libganglia-3.5.0-99'] {}\n2014-05-29 04:42:31,614 - Skipping installing existent package libganglia-3.5.0-99\n2014-05-29 04:42:31,614 - Package['ganglia-devel-3.5.0-99'] {}\n2014-05-29 04:42:31,638 - Skipping installing existent package ganglia-devel-3.5.0-99\n2014-05-29 04:42:31,638 - Package['ganglia-gmetad-3.5.0-99'] {}\n2014-05-29 04:42:31,662 - Skipping installing existent package ganglia-gmetad-3.5.0-99\n2014-05-29 04:42:31,662 - Package['ganglia-web-3.5.7-99.noarch'] {}\n2014-05-29 04:42:31,689 - Skipping installing existent package ganglia-web-3.5.7-99.noarch\n2014-05-29 04:42:31,689 - Package['python-rrdtool.x86_64'] {}\n2014-05-29 04:42:31,714 - Skipping installing existent package python-rrdtool.x86_64\n2014-05-29 04:42:31,715 - Package['ganglia-gmond-3.5.0-99'] {}\n2014-05-29 04:42:31,739 - Skipping installing existent package ganglia-gmond-3.5.0-99\n2014-05-29 04:42:31,739 - Package['ganglia-gmond-modules-python-3.5.0-99'] {}\n2014-05-29 04:42:31,764 - Skipping installing existent package ganglia-gmond-modules-python-3.5.0-99\n2014-05-29 04:42:31,764 - Package['httpd'] {}\n2014-05-29 04:42:31,790 - Skipping installing existent package httpd\n2014-05-29 04:42:31,791 - Directory['/usr/libexec/hdp/ganglia'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:42:31,791 - File['/etc/init.d/hdp-gmetad'] {'content': StaticFile('gmetad.init'), 'mode': 0755}\n2014-05-29 04:42:31,792 - File['/etc/init.d/hdp-gmond'] {'content': StaticFile('gmond.init'), 'mode': 0755}\n2014-05-29 04:42:31,792 - File['/usr/libexec/hdp/ganglia/checkGmond.sh'] {'content': StaticFile('checkGmond.sh'), 'mode': 0755}\n2014-05-29 04:42:31,793 - File['/usr/libexec/hdp/ganglia/checkRrdcached.sh'] {'content': StaticFile('checkRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:42:31,793 - File['/usr/libexec/hdp/ganglia/gmetadLib.sh'] {'content': StaticFile('gmetadLib.sh'), 'mode': 0755}\n2014-05-29 04:42:31,793 - File['/usr/libexec/hdp/ganglia/gmondLib.sh'] {'content': StaticFile('gmondLib.sh'), 'mode': 0755}\n2014-05-29 04:42:31,794 - File['/usr/libexec/hdp/ganglia/rrdcachedLib.sh'] {'content': StaticFile('rrdcachedLib.sh'), 'mode': 0755}\n2014-05-29 04:42:31,794 - File['/usr/libexec/hdp/ganglia/setupGanglia.sh'] {'content': StaticFile('setupGanglia.sh'), 'mode': 0755}\n2014-05-29 04:42:31,794 - File['/usr/libexec/hdp/ganglia/startGmetad.sh'] {'content': StaticFile('startGmetad.sh'), 'mode': 0755}\n2014-05-29 04:42:31,795 - File['/usr/libexec/hdp/ganglia/startGmond.sh'] {'content': StaticFile('startGmond.sh'), 'mode': 0755}\n2014-05-29 04:42:31,795 - File['/usr/libexec/hdp/ganglia/startRrdcached.sh'] {'content': StaticFile('startRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:42:31,795 - File['/usr/libexec/hdp/ganglia/stopGmetad.sh'] {'content': StaticFile('stopGmetad.sh'), 'mode': 0755}\n2014-05-29 04:42:31,796 - File['/usr/libexec/hdp/ganglia/stopGmond.sh'] {'content': StaticFile('stopGmond.sh'), 'mode': 0755}\n2014-05-29 04:42:31,796 - File['/usr/libexec/hdp/ganglia/stopRrdcached.sh'] {'content': StaticFile('stopRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:42:31,797 - File['/usr/libexec/hdp/ganglia/teardownGanglia.sh'] {'content': StaticFile('teardownGanglia.sh'), 'mode': 0755}\n2014-05-29 04:42:31,797 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:31,802 - File['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] {'content': Template('gangliaClusters.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:31,803 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:31,805 - File['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] {'content': Template('gangliaEnv.sh.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:31,806 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaLib.sh'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:31,808 - File['/usr/libexec/hdp/ganglia/gangliaLib.sh'] {'content': Template('gangliaLib.sh.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:42:31,809 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -t -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:42:31,860 - Directory['/var/lib/ganglia/dwoo'] {'owner': 'nobody', 'recursive': True, 'mode': 0777}\n2014-05-29 04:42:31,861 - Creating directory Directory['/var/lib/ganglia/dwoo']\n2014-05-29 04:42:31,861 - Changing permission for /var/lib/ganglia/dwoo from 755 to 777\n2014-05-29 04:42:31,861 - Changing owner for /var/lib/ganglia/dwoo from 0 to nobody\n2014-05-29 04:42:31,861 - Directory['/var/www/cgi-bin'] {'recursive': True}\n2014-05-29 04:42:31,861 - File['/var/www/cgi-bin/rrd.py'] {'content': StaticFile('rrd.py'), 'mode': 0755}\n2014-05-29 04:42:31,870 - Writing File['/var/www/cgi-bin/rrd.py'] because it doesn't exist\n2014-05-29 04:42:31,870 - Changing permission for /var/www/cgi-bin/rrd.py from 644 to 755\n2014-05-29 04:42:31,871 - File['/etc/ganglia/gmetad.conf'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:42:31,871 - Changing group for /etc/ganglia/gmetad.conf from 0 to hadoop\n2014-05-29 04:42:31,871 - Execute['chkconfig gmetad off'] {'path': ['/usr/sbin:/sbin:/usr/local/bin:/bin:/usr/bin']}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/5",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "HDFS_CLIENT INSTALL",
        "end_time" : 1401352952985,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 5,
        "request_id" : 1,
        "role" : "HDFS_CLIENT",
        "stage_id" : 1,
        "start_time" : 1401352497875,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:42:32,020 - Group['hadoop'] {}\n2014-05-29 04:42:32,022 - Modifying group hadoop\n2014-05-29 04:42:32,058 - Group['users'] {}\n2014-05-29 04:42:32,059 - Modifying group users\n2014-05-29 04:42:32,088 - Group['users'] {}\n2014-05-29 04:42:32,088 - Modifying group users\n2014-05-29 04:42:32,115 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:42:32,115 - Modifying user ambari-qa\n2014-05-29 04:42:32,144 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:42:32,147 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:42:32,164 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:42:32,165 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:42:32,165 - Modifying user yarn\n2014-05-29 04:42:32,187 - Group['nobody'] {}\n2014-05-29 04:42:32,187 - Modifying group nobody\n2014-05-29 04:42:32,229 - Group['nobody'] {}\n2014-05-29 04:42:32,230 - Modifying group nobody\n2014-05-29 04:42:32,257 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:42:32,257 - Modifying user nobody\n2014-05-29 04:42:32,278 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:42:32,278 - Modifying user nobody\n2014-05-29 04:42:32,299 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:42:32,299 - Modifying user hdfs\n2014-05-29 04:42:32,320 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:42:32,321 - Modifying user mapred\n2014-05-29 04:42:32,344 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:42:32,344 - Modifying user zookeeper\n2014-05-29 04:42:32,364 - Package['unzip'] {}\n2014-05-29 04:42:32,388 - Skipping installing existent package unzip\n2014-05-29 04:42:32,388 - Package['net-snmp'] {}\n2014-05-29 04:42:32,415 - Skipping installing existent package net-snmp\n2014-05-29 04:42:32,415 - Package['net-snmp-utils'] {}\n2014-05-29 04:42:32,439 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:42:32,557 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:42:32,562 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:42:32,564 - Package['lzo'] {}\n2014-05-29 04:42:32,588 - Skipping installing existent package lzo\n2014-05-29 04:42:32,588 - Package['hadoop'] {}\n2014-05-29 04:42:32,611 - Skipping installing existent package hadoop\n2014-05-29 04:42:32,612 - Package['hadoop-libhdfs'] {}\n2014-05-29 04:42:32,638 - Skipping installing existent package hadoop-libhdfs\n2014-05-29 04:42:32,638 - Package['hadoop-lzo'] {}\n2014-05-29 04:42:32,661 - Skipping installing existent package hadoop-lzo\n2014-05-29 04:42:32,661 - Package['hadoop-lzo-native'] {}\n2014-05-29 04:42:32,684 - Skipping installing existent package hadoop-lzo-native\n2014-05-29 04:42:32,684 - Package['snappy'] {}\n2014-05-29 04:42:32,708 - Skipping installing existent package snappy\n2014-05-29 04:42:32,709 - Package['snappy-devel'] {}\n2014-05-29 04:42:32,732 - Skipping installing existent package snappy-devel\n2014-05-29 04:42:32,734 - Package['ambari-log4j'] {}\n2014-05-29 04:42:32,757 - Skipping installing existent package ambari-log4j\n2014-05-29 04:42:32,759 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:42:32,764 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:42:32,764 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:42:32,765 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:42:32,766 - Changing owner for /etc/hadoop/conf/core-site.xml from 0 to hdfs\n2014-05-29 04:42:32,766 - Changing group for /etc/hadoop/conf/core-site.xml from 0 to hadoop\n2014-05-29 04:42:32,766 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:42:32,769 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:42:32,769 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:42:32,770 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:42:32,770 - Changing owner for /etc/hadoop/conf/hdfs-site.xml from 0 to hdfs\n2014-05-29 04:42:32,770 - Changing group for /etc/hadoop/conf/hdfs-site.xml from 0 to hadoop",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/6",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "HISTORYSERVER INSTALL",
        "end_time" : 1401353067605,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 6,
        "request_id" : 1,
        "role" : "HISTORYSERVER",
        "stage_id" : 1,
        "start_time" : 1401352497893,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:42:32,892 - Group['hadoop'] {}\n2014-05-29 04:42:32,893 - Modifying group hadoop\n2014-05-29 04:42:32,929 - Group['users'] {}\n2014-05-29 04:42:32,930 - Modifying group users\n2014-05-29 04:42:32,956 - Group['users'] {}\n2014-05-29 04:42:32,956 - Modifying group users\n2014-05-29 04:42:32,982 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:42:32,984 - Modifying user ambari-qa\n2014-05-29 04:42:33,009 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:42:33,010 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:42:33,024 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:42:33,024 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:42:33,024 - Modifying user yarn\n2014-05-29 04:42:33,045 - Group['nobody'] {}\n2014-05-29 04:42:33,045 - Modifying group nobody\n2014-05-29 04:42:33,070 - Group['nobody'] {}\n2014-05-29 04:42:33,071 - Modifying group nobody\n2014-05-29 04:42:33,097 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:42:33,097 - Modifying user nobody\n2014-05-29 04:42:33,118 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:42:33,118 - Modifying user nobody\n2014-05-29 04:42:33,139 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:42:33,140 - Modifying user hdfs\n2014-05-29 04:42:33,162 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:42:33,163 - Modifying user mapred\n2014-05-29 04:42:33,185 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:42:33,185 - Modifying user zookeeper\n2014-05-29 04:42:33,207 - Package['unzip'] {}\n2014-05-29 04:42:33,230 - Skipping installing existent package unzip\n2014-05-29 04:42:33,231 - Package['net-snmp'] {}\n2014-05-29 04:42:33,255 - Skipping installing existent package net-snmp\n2014-05-29 04:42:33,255 - Package['net-snmp-utils'] {}\n2014-05-29 04:42:33,277 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:42:33,366 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:42:33,372 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:42:33,373 - Package['hadoop-mapreduce'] {}\n2014-05-29 04:42:33,397 - Installing package hadoop-mapreduce ('/usr/bin/yum -d 0 -e 0 -y install hadoop-mapreduce')\n2014-05-29 04:44:26,384 - Package['hadoop-mapreduce-historyserver'] {}\n2014-05-29 04:44:26,416 - Installing package hadoop-mapreduce-historyserver ('/usr/bin/yum -d 0 -e 0 -y install hadoop-mapreduce-historyserver')",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/7",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "MAPREDUCE2_CLIENT INSTALL",
        "end_time" : 1401353070057,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 7,
        "request_id" : 1,
        "role" : "MAPREDUCE2_CLIENT",
        "stage_id" : 1,
        "start_time" : 1401352497916,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:29,247 - Group['hadoop'] {}\n2014-05-29 04:44:29,248 - Modifying group hadoop\n2014-05-29 04:44:29,283 - Group['users'] {}\n2014-05-29 04:44:29,283 - Modifying group users\n2014-05-29 04:44:29,308 - Group['users'] {}\n2014-05-29 04:44:29,309 - Modifying group users\n2014-05-29 04:44:29,339 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:29,339 - Modifying user ambari-qa\n2014-05-29 04:44:29,367 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:29,368 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:29,384 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:29,384 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:29,384 - Modifying user yarn\n2014-05-29 04:44:29,406 - Group['nobody'] {}\n2014-05-29 04:44:29,407 - Modifying group nobody\n2014-05-29 04:44:29,432 - Group['nobody'] {}\n2014-05-29 04:44:29,433 - Modifying group nobody\n2014-05-29 04:44:29,459 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:29,460 - Modifying user nobody\n2014-05-29 04:44:29,483 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:29,483 - Modifying user nobody\n2014-05-29 04:44:29,506 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:29,506 - Modifying user hdfs\n2014-05-29 04:44:29,528 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:29,529 - Modifying user mapred\n2014-05-29 04:44:29,551 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:29,552 - Modifying user zookeeper\n2014-05-29 04:44:29,576 - Package['unzip'] {}\n2014-05-29 04:44:29,602 - Skipping installing existent package unzip\n2014-05-29 04:44:29,602 - Package['net-snmp'] {}\n2014-05-29 04:44:29,626 - Skipping installing existent package net-snmp\n2014-05-29 04:44:29,627 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:29,648 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:29,772 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:29,779 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:29,780 - Package['hadoop-mapreduce'] {}\n2014-05-29 04:44:29,804 - Skipping installing existent package hadoop-mapreduce\n2014-05-29 04:44:29,804 - Package['hadoop-mapreduce-historyserver'] {}\n2014-05-29 04:44:29,826 - Skipping installing existent package hadoop-mapreduce-historyserver\n2014-05-29 04:44:29,841 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:29,844 - Creating directory Directory['/var/run/hadoop-yarn/yarn']\n2014-05-29 04:44:29,845 - Changing owner for /var/run/hadoop-yarn/yarn from 0 to yarn\n2014-05-29 04:44:29,846 - Changing group for /var/run/hadoop-yarn/yarn from 0 to hadoop\n2014-05-29 04:44:29,846 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:29,847 - Creating directory Directory['/var/log/hadoop-yarn/yarn']\n2014-05-29 04:44:29,847 - Changing owner for /var/log/hadoop-yarn/yarn from 0 to yarn\n2014-05-29 04:44:29,847 - Changing group for /var/log/hadoop-yarn/yarn from 0 to hadoop\n2014-05-29 04:44:29,847 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:29,847 - Creating directory Directory['/var/run/hadoop-mapreduce/mapred']\n2014-05-29 04:44:29,848 - Changing owner for /var/run/hadoop-mapreduce/mapred from 0 to mapred\n2014-05-29 04:44:29,848 - Changing group for /var/run/hadoop-mapreduce/mapred from 0 to hadoop\n2014-05-29 04:44:29,848 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:29,848 - Creating directory Directory['/var/log/hadoop-mapreduce/mapred']\n2014-05-29 04:44:29,848 - Changing owner for /var/log/hadoop-mapreduce/mapred from 0 to mapred\n2014-05-29 04:44:29,848 - Changing group for /var/log/hadoop-mapreduce/mapred from 0 to hadoop\n2014-05-29 04:44:29,849 - Directory['/hadoop/yarn/local'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:29,849 - Creating directory Directory['/hadoop/yarn/local']\n2014-05-29 04:44:29,849 - Changing owner for /hadoop/yarn/local from 0 to yarn\n2014-05-29 04:44:29,849 - Directory['/hadoop/yarn/log'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:29,849 - Creating directory Directory['/hadoop/yarn/log']\n2014-05-29 04:44:29,850 - Changing owner for /hadoop/yarn/log from 0 to yarn\n2014-05-29 04:44:29,850 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:29,850 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:29,855 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:44:29,855 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:29,856 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:44:29,857 - XmlConfig['mapred-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:29,861 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:44:29,861 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:29,864 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:44:29,864 - Changing owner for /etc/hadoop/conf/mapred-site.xml from 0 to yarn\n2014-05-29 04:44:29,864 - Changing group for /etc/hadoop/conf/mapred-site.xml from 0 to hadoop\n2014-05-29 04:44:29,865 - XmlConfig['yarn-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:29,868 - Generating config: /etc/hadoop/conf/yarn-site.xml\n2014-05-29 04:44:29,868 - File['/etc/hadoop/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:29,869 - Writing File['/etc/hadoop/conf/yarn-site.xml'] because contents don't match\n2014-05-29 04:44:29,870 - Changing owner for /etc/hadoop/conf/yarn-site.xml from 0 to yarn\n2014-05-29 04:44:29,870 - Changing group for /etc/hadoop/conf/yarn-site.xml from 0 to hadoop\n2014-05-29 04:44:29,870 - XmlConfig['capacity-scheduler.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:29,873 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:44:29,873 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:29,874 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:44:29,874 - Changing owner for /etc/hadoop/conf/capacity-scheduler.xml from 0 to yarn\n2014-05-29 04:44:29,874 - Changing group for /etc/hadoop/conf/capacity-scheduler.xml from 0 to hadoop\n2014-05-29 04:44:29,874 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:44:29,875 - Writing File['/etc/hadoop/conf/yarn.exclude'] because it doesn't exist\n2014-05-29 04:44:29,875 - Changing owner for /etc/hadoop/conf/yarn.exclude from 0 to yarn\n2014-05-29 04:44:29,875 - Changing group for /etc/hadoop/conf/yarn.exclude from 0 to hadoop\n2014-05-29 04:44:29,879 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:29,880 - Writing File['/etc/security/limits.d/yarn.conf'] because contents don't match\n2014-05-29 04:44:29,882 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:29,883 - Writing File['/etc/security/limits.d/mapreduce.conf'] because contents don't match\n2014-05-29 04:44:29,888 - File['/etc/hadoop/conf/yarn-env.sh'] {'content': Template('yarn-env.sh.j2'), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}\n2014-05-29 04:44:29,889 - Writing File['/etc/hadoop/conf/yarn-env.sh'] because contents don't match\n2014-05-29 04:44:29,889 - Changing permission for /etc/hadoop/conf/yarn-env.sh from 644 to 755\n2014-05-29 04:44:29,889 - Changing owner for /etc/hadoop/conf/yarn-env.sh from 0 to yarn\n2014-05-29 04:44:29,889 - Changing group for /etc/hadoop/conf/yarn-env.sh from 0 to hadoop",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/8",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "NAMENODE INSTALL",
        "end_time" : 1401353070957,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 8,
        "request_id" : 1,
        "role" : "NAMENODE",
        "stage_id" : 1,
        "start_time" : 1401352497932,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:30,015 - Group['hadoop'] {}\n2014-05-29 04:44:30,016 - Modifying group hadoop\n2014-05-29 04:44:30,050 - Group['users'] {}\n2014-05-29 04:44:30,051 - Modifying group users\n2014-05-29 04:44:30,079 - Group['users'] {}\n2014-05-29 04:44:30,080 - Modifying group users\n2014-05-29 04:44:30,105 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:30,105 - Modifying user ambari-qa\n2014-05-29 04:44:30,129 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:30,131 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:30,147 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:30,147 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:30,147 - Modifying user yarn\n2014-05-29 04:44:30,166 - Group['nobody'] {}\n2014-05-29 04:44:30,167 - Modifying group nobody\n2014-05-29 04:44:30,198 - Group['nobody'] {}\n2014-05-29 04:44:30,199 - Modifying group nobody\n2014-05-29 04:44:30,234 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:30,235 - Modifying user nobody\n2014-05-29 04:44:30,262 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:30,262 - Modifying user nobody\n2014-05-29 04:44:30,288 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:30,289 - Modifying user hdfs\n2014-05-29 04:44:30,311 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:30,312 - Modifying user mapred\n2014-05-29 04:44:30,332 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:30,332 - Modifying user zookeeper\n2014-05-29 04:44:30,359 - Package['unzip'] {}\n2014-05-29 04:44:30,384 - Skipping installing existent package unzip\n2014-05-29 04:44:30,384 - Package['net-snmp'] {}\n2014-05-29 04:44:30,410 - Skipping installing existent package net-snmp\n2014-05-29 04:44:30,410 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:30,435 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:30,542 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:30,550 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:30,552 - Package['lzo'] {}\n2014-05-29 04:44:30,579 - Skipping installing existent package lzo\n2014-05-29 04:44:30,579 - Package['hadoop'] {}\n2014-05-29 04:44:30,603 - Skipping installing existent package hadoop\n2014-05-29 04:44:30,603 - Package['hadoop-libhdfs'] {}\n2014-05-29 04:44:30,626 - Skipping installing existent package hadoop-libhdfs\n2014-05-29 04:44:30,626 - Package['hadoop-lzo'] {}\n2014-05-29 04:44:30,649 - Skipping installing existent package hadoop-lzo\n2014-05-29 04:44:30,649 - Package['hadoop-lzo-native'] {}\n2014-05-29 04:44:30,680 - Skipping installing existent package hadoop-lzo-native\n2014-05-29 04:44:30,681 - Package['snappy'] {}\n2014-05-29 04:44:30,714 - Skipping installing existent package snappy\n2014-05-29 04:44:30,714 - Package['snappy-devel'] {}\n2014-05-29 04:44:30,737 - Skipping installing existent package snappy-devel\n2014-05-29 04:44:30,738 - Package['ambari-log4j'] {}\n2014-05-29 04:44:30,763 - Skipping installing existent package ambari-log4j\n2014-05-29 04:44:30,765 - Directory['/hadoop/hdfs/namenode'] {'owner': 'hdfs', 'group': 'hadoop', 'recursive': True, 'mode': 0755}\n2014-05-29 04:44:30,765 - Creating directory Directory['/hadoop/hdfs/namenode']\n2014-05-29 04:44:30,767 - Changing owner for /hadoop/hdfs/namenode from 0 to hdfs\n2014-05-29 04:44:30,768 - Changing group for /hadoop/hdfs/namenode from 0 to hadoop",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/9",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "NODEMANAGER INSTALL",
        "end_time" : 1401353074942,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 9,
        "request_id" : 1,
        "role" : "NODEMANAGER",
        "stage_id" : 1,
        "start_time" : 1401352497946,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:30,899 - Group['hadoop'] {}\n2014-05-29 04:44:30,900 - Modifying group hadoop\n2014-05-29 04:44:30,937 - Group['users'] {}\n2014-05-29 04:44:30,938 - Modifying group users\n2014-05-29 04:44:30,964 - Group['users'] {}\n2014-05-29 04:44:30,965 - Modifying group users\n2014-05-29 04:44:30,991 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:30,991 - Modifying user ambari-qa\n2014-05-29 04:44:31,020 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:31,021 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:31,041 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:31,041 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:31,041 - Modifying user yarn\n2014-05-29 04:44:31,070 - Group['nobody'] {}\n2014-05-29 04:44:31,070 - Modifying group nobody\n2014-05-29 04:44:31,108 - Group['nobody'] {}\n2014-05-29 04:44:31,108 - Modifying group nobody\n2014-05-29 04:44:31,136 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:31,137 - Modifying user nobody\n2014-05-29 04:44:31,158 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:31,158 - Modifying user nobody\n2014-05-29 04:44:31,179 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:31,179 - Modifying user hdfs\n2014-05-29 04:44:31,201 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:31,201 - Modifying user mapred\n2014-05-29 04:44:31,222 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:31,223 - Modifying user zookeeper\n2014-05-29 04:44:31,242 - Package['unzip'] {}\n2014-05-29 04:44:31,268 - Skipping installing existent package unzip\n2014-05-29 04:44:31,269 - Package['net-snmp'] {}\n2014-05-29 04:44:31,293 - Skipping installing existent package net-snmp\n2014-05-29 04:44:31,293 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:31,317 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:31,409 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:31,414 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:31,415 - Package['hadoop-yarn'] {}\n2014-05-29 04:44:31,439 - Skipping installing existent package hadoop-yarn\n2014-05-29 04:44:31,439 - Package['hadoop-yarn-nodemanager'] {}\n2014-05-29 04:44:31,470 - Installing package hadoop-yarn-nodemanager ('/usr/bin/yum -d 0 -e 0 -y install hadoop-yarn-nodemanager')\n2014-05-29 04:44:32,671 - Package['hadoop-mapreduce'] {}\n2014-05-29 04:44:32,694 - Skipping installing existent package hadoop-mapreduce\n2014-05-29 04:44:32,694 - Package['hadoop-yarn-proxyserver'] {}\n2014-05-29 04:44:32,716 - Installing package hadoop-yarn-proxyserver ('/usr/bin/yum -d 0 -e 0 -y install hadoop-yarn-proxyserver')\n2014-05-29 04:44:33,625 - Package['hadoop-yarn-resourcemanager'] {}\n2014-05-29 04:44:33,648 - Installing package hadoop-yarn-resourcemanager ('/usr/bin/yum -d 0 -e 0 -y install hadoop-yarn-resourcemanager')",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/10",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "RESOURCEMANAGER INSTALL",
        "end_time" : 1401353075854,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 10,
        "request_id" : 1,
        "role" : "RESOURCEMANAGER",
        "stage_id" : 1,
        "start_time" : 1401352497965,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:34,895 - Group['hadoop'] {}\n2014-05-29 04:44:34,896 - Modifying group hadoop\n2014-05-29 04:44:34,936 - Group['users'] {}\n2014-05-29 04:44:34,936 - Modifying group users\n2014-05-29 04:44:34,968 - Group['users'] {}\n2014-05-29 04:44:34,969 - Modifying group users\n2014-05-29 04:44:34,994 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:34,994 - Modifying user ambari-qa\n2014-05-29 04:44:35,020 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:35,021 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:35,039 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:35,039 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:35,040 - Modifying user yarn\n2014-05-29 04:44:35,059 - Group['nobody'] {}\n2014-05-29 04:44:35,060 - Modifying group nobody\n2014-05-29 04:44:35,087 - Group['nobody'] {}\n2014-05-29 04:44:35,088 - Modifying group nobody\n2014-05-29 04:44:35,116 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:35,116 - Modifying user nobody\n2014-05-29 04:44:35,137 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:35,138 - Modifying user nobody\n2014-05-29 04:44:35,158 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:35,159 - Modifying user hdfs\n2014-05-29 04:44:35,188 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:35,188 - Modifying user mapred\n2014-05-29 04:44:35,210 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:35,210 - Modifying user zookeeper\n2014-05-29 04:44:35,229 - Package['unzip'] {}\n2014-05-29 04:44:35,254 - Skipping installing existent package unzip\n2014-05-29 04:44:35,254 - Package['net-snmp'] {}\n2014-05-29 04:44:35,287 - Skipping installing existent package net-snmp\n2014-05-29 04:44:35,287 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:35,317 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:35,420 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:35,430 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:35,432 - Package['hadoop-yarn'] {}\n2014-05-29 04:44:35,464 - Skipping installing existent package hadoop-yarn\n2014-05-29 04:44:35,465 - Package['hadoop-yarn-nodemanager'] {}\n2014-05-29 04:44:35,491 - Skipping installing existent package hadoop-yarn-nodemanager\n2014-05-29 04:44:35,491 - Package['hadoop-mapreduce'] {}\n2014-05-29 04:44:35,520 - Skipping installing existent package hadoop-mapreduce\n2014-05-29 04:44:35,521 - Package['hadoop-yarn-proxyserver'] {}\n2014-05-29 04:44:35,550 - Skipping installing existent package hadoop-yarn-proxyserver\n2014-05-29 04:44:35,550 - Package['hadoop-yarn-resourcemanager'] {}\n2014-05-29 04:44:35,575 - Skipping installing existent package hadoop-yarn-resourcemanager\n2014-05-29 04:44:35,579 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:35,580 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:35,581 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:35,581 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:35,581 - Directory['/hadoop/yarn/local'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:35,582 - Directory['/hadoop/yarn/log'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:35,582 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:35,583 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:35,587 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:44:35,588 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:35,588 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:44:35,589 - XmlConfig['mapred-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:35,596 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:44:35,597 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:35,598 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:44:35,598 - XmlConfig['yarn-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:35,601 - Generating config: /etc/hadoop/conf/yarn-site.xml\n2014-05-29 04:44:35,602 - File['/etc/hadoop/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:35,603 - Writing File['/etc/hadoop/conf/yarn-site.xml'] because contents don't match\n2014-05-29 04:44:35,603 - XmlConfig['capacity-scheduler.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:35,606 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:44:35,606 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:35,607 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:44:35,607 - File['/var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:44:35,608 - Writing File['/var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log'] because it doesn't exist\n2014-05-29 04:44:35,608 - Changing owner for /var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log from 0 to yarn\n2014-05-29 04:44:35,608 - Changing group for /var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log from 0 to hadoop\n2014-05-29 04:44:35,608 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:44:35,611 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:35,616 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:35,620 - File['/etc/hadoop/conf/yarn-env.sh'] {'content': Template('yarn-env.sh.j2'), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/11",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "SECONDARY_NAMENODE INSTALL",
        "end_time" : 1401353076870,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 11,
        "request_id" : 1,
        "role" : "SECONDARY_NAMENODE",
        "stage_id" : 1,
        "start_time" : 1401352497980,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:35,774 - Group['hadoop'] {}\n2014-05-29 04:44:35,775 - Modifying group hadoop\n2014-05-29 04:44:35,808 - Group['users'] {}\n2014-05-29 04:44:35,808 - Modifying group users\n2014-05-29 04:44:35,835 - Group['users'] {}\n2014-05-29 04:44:35,836 - Modifying group users\n2014-05-29 04:44:35,870 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:35,871 - Modifying user ambari-qa\n2014-05-29 04:44:35,895 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:35,897 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:35,911 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:35,911 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:35,912 - Modifying user yarn\n2014-05-29 04:44:35,941 - Group['nobody'] {}\n2014-05-29 04:44:35,942 - Modifying group nobody\n2014-05-29 04:44:35,969 - Group['nobody'] {}\n2014-05-29 04:44:35,970 - Modifying group nobody\n2014-05-29 04:44:35,999 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:35,999 - Modifying user nobody\n2014-05-29 04:44:36,028 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:36,028 - Modifying user nobody\n2014-05-29 04:44:36,049 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:36,049 - Modifying user hdfs\n2014-05-29 04:44:36,071 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:36,071 - Modifying user mapred\n2014-05-29 04:44:36,099 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:36,099 - Modifying user zookeeper\n2014-05-29 04:44:36,121 - Package['unzip'] {}\n2014-05-29 04:44:36,144 - Skipping installing existent package unzip\n2014-05-29 04:44:36,145 - Package['net-snmp'] {}\n2014-05-29 04:44:36,168 - Skipping installing existent package net-snmp\n2014-05-29 04:44:36,169 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:36,205 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:36,364 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:36,370 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:36,372 - Package['lzo'] {}\n2014-05-29 04:44:36,396 - Skipping installing existent package lzo\n2014-05-29 04:44:36,397 - Package['hadoop'] {}\n2014-05-29 04:44:36,428 - Skipping installing existent package hadoop\n2014-05-29 04:44:36,429 - Package['hadoop-libhdfs'] {}\n2014-05-29 04:44:36,459 - Skipping installing existent package hadoop-libhdfs\n2014-05-29 04:44:36,459 - Package['hadoop-lzo'] {}\n2014-05-29 04:44:36,483 - Skipping installing existent package hadoop-lzo\n2014-05-29 04:44:36,483 - Package['hadoop-lzo-native'] {}\n2014-05-29 04:44:36,510 - Skipping installing existent package hadoop-lzo-native\n2014-05-29 04:44:36,511 - Package['snappy'] {}\n2014-05-29 04:44:36,538 - Skipping installing existent package snappy\n2014-05-29 04:44:36,538 - Package['snappy-devel'] {}\n2014-05-29 04:44:36,573 - Skipping installing existent package snappy-devel\n2014-05-29 04:44:36,573 - Package['ambari-log4j'] {}\n2014-05-29 04:44:36,610 - Skipping installing existent package ambari-log4j",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/12",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "YARN_CLIENT INSTALL",
        "end_time" : 1401353077726,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 12,
        "request_id" : 1,
        "role" : "YARN_CLIENT",
        "stage_id" : 1,
        "start_time" : 1401352498001,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:36,750 - Group['hadoop'] {}\n2014-05-29 04:44:36,751 - Modifying group hadoop\n2014-05-29 04:44:36,792 - Group['users'] {}\n2014-05-29 04:44:36,792 - Modifying group users\n2014-05-29 04:44:36,818 - Group['users'] {}\n2014-05-29 04:44:36,819 - Modifying group users\n2014-05-29 04:44:36,851 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:36,851 - Modifying user ambari-qa\n2014-05-29 04:44:36,880 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:36,881 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:36,899 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:36,899 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:36,900 - Modifying user yarn\n2014-05-29 04:44:36,927 - Group['nobody'] {}\n2014-05-29 04:44:36,929 - Modifying group nobody\n2014-05-29 04:44:36,958 - Group['nobody'] {}\n2014-05-29 04:44:36,959 - Modifying group nobody\n2014-05-29 04:44:36,984 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:36,984 - Modifying user nobody\n2014-05-29 04:44:37,009 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:37,010 - Modifying user nobody\n2014-05-29 04:44:37,037 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:37,038 - Modifying user hdfs\n2014-05-29 04:44:37,063 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:37,063 - Modifying user mapred\n2014-05-29 04:44:37,089 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:37,090 - Modifying user zookeeper\n2014-05-29 04:44:37,113 - Package['unzip'] {}\n2014-05-29 04:44:37,138 - Skipping installing existent package unzip\n2014-05-29 04:44:37,138 - Package['net-snmp'] {}\n2014-05-29 04:44:37,161 - Skipping installing existent package net-snmp\n2014-05-29 04:44:37,161 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:37,202 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:37,320 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:37,325 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:37,326 - Package['hadoop-yarn'] {}\n2014-05-29 04:44:37,357 - Skipping installing existent package hadoop-yarn\n2014-05-29 04:44:37,358 - Package['hadoop-yarn-nodemanager'] {}\n2014-05-29 04:44:37,381 - Skipping installing existent package hadoop-yarn-nodemanager\n2014-05-29 04:44:37,381 - Package['hadoop-mapreduce'] {}\n2014-05-29 04:44:37,404 - Skipping installing existent package hadoop-mapreduce\n2014-05-29 04:44:37,404 - Package['hadoop-yarn-proxyserver'] {}\n2014-05-29 04:44:37,435 - Skipping installing existent package hadoop-yarn-proxyserver\n2014-05-29 04:44:37,435 - Package['hadoop-yarn-resourcemanager'] {}\n2014-05-29 04:44:37,459 - Skipping installing existent package hadoop-yarn-resourcemanager\n2014-05-29 04:44:37,464 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:37,464 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:37,465 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:37,465 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:37,465 - Directory['/hadoop/yarn/local'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:37,465 - Directory['/hadoop/yarn/log'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:37,466 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:37,466 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:37,469 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:44:37,469 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:37,470 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:44:37,470 - XmlConfig['mapred-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:37,474 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:44:37,474 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:37,475 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:44:37,476 - XmlConfig['yarn-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:37,479 - Generating config: /etc/hadoop/conf/yarn-site.xml\n2014-05-29 04:44:37,479 - File['/etc/hadoop/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:37,480 - Writing File['/etc/hadoop/conf/yarn-site.xml'] because contents don't match\n2014-05-29 04:44:37,481 - XmlConfig['capacity-scheduler.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:37,484 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:44:37,484 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:37,485 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:44:37,486 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:44:37,488 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:37,490 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:37,494 - File['/etc/hadoop/conf/yarn-env.sh'] {'content': Template('yarn-env.sh.j2'), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/13",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "ZOOKEEPER_CLIENT INSTALL",
        "end_time" : 1401353078528,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 13,
        "request_id" : 1,
        "role" : "ZOOKEEPER_CLIENT",
        "stage_id" : 1,
        "start_time" : 1401352498014,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:37,657 - Group['hadoop'] {}\n2014-05-29 04:44:37,658 - Modifying group hadoop\n2014-05-29 04:44:37,701 - Group['users'] {}\n2014-05-29 04:44:37,701 - Modifying group users\n2014-05-29 04:44:37,729 - Group['users'] {}\n2014-05-29 04:44:37,729 - Modifying group users\n2014-05-29 04:44:37,756 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:37,757 - Modifying user ambari-qa\n2014-05-29 04:44:37,784 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:37,785 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:37,800 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:37,800 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:37,801 - Modifying user yarn\n2014-05-29 04:44:37,821 - Group['nobody'] {}\n2014-05-29 04:44:37,822 - Modifying group nobody\n2014-05-29 04:44:37,862 - Group['nobody'] {}\n2014-05-29 04:44:37,863 - Modifying group nobody\n2014-05-29 04:44:37,889 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:37,889 - Modifying user nobody\n2014-05-29 04:44:37,912 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:37,912 - Modifying user nobody\n2014-05-29 04:44:37,944 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:37,945 - Modifying user hdfs\n2014-05-29 04:44:37,968 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:37,968 - Modifying user mapred\n2014-05-29 04:44:37,990 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:37,990 - Modifying user zookeeper\n2014-05-29 04:44:38,018 - Package['unzip'] {}\n2014-05-29 04:44:38,041 - Skipping installing existent package unzip\n2014-05-29 04:44:38,042 - Package['net-snmp'] {}\n2014-05-29 04:44:38,065 - Skipping installing existent package net-snmp\n2014-05-29 04:44:38,066 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:38,094 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:38,262 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:38,269 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:38,271 - Package['zookeeper'] {}\n2014-05-29 04:44:38,308 - Skipping installing existent package zookeeper\n2014-05-29 04:44:38,320 - Directory['/etc/zookeeper/conf'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:38,322 - Changing owner for /etc/zookeeper/conf from 0 to zookeeper\n2014-05-29 04:44:38,322 - Changing group for /etc/zookeeper/conf from 0 to hadoop\n2014-05-29 04:44:38,334 - File['/etc/zookeeper/conf/zoo.cfg'] {'owner': 'zookeeper', 'content': Template('zoo.cfg.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:38,335 - Writing File['/etc/zookeeper/conf/zoo.cfg'] because contents don't match\n2014-05-29 04:44:38,335 - Changing owner for /etc/zookeeper/conf/zoo.cfg from 0 to zookeeper\n2014-05-29 04:44:38,336 - Changing group for /etc/zookeeper/conf/zoo.cfg from 0 to hadoop\n2014-05-29 04:44:38,339 - File['/etc/zookeeper/conf/zookeeper-env.sh'] {'owner': 'zookeeper', 'content': Template('zookeeper-env.sh.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:38,340 - Writing File['/etc/zookeeper/conf/zookeeper-env.sh'] because contents don't match\n2014-05-29 04:44:38,340 - Changing owner for /etc/zookeeper/conf/zookeeper-env.sh from 0 to zookeeper\n2014-05-29 04:44:38,340 - Changing group for /etc/zookeeper/conf/zookeeper-env.sh from 0 to hadoop\n2014-05-29 04:44:38,342 - File['/etc/zookeeper/conf/configuration.xsl'] {'owner': 'zookeeper', 'content': Template('configuration.xsl.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:38,343 - Writing File['/etc/zookeeper/conf/configuration.xsl'] because contents don't match\n2014-05-29 04:44:38,344 - Changing owner for /etc/zookeeper/conf/configuration.xsl from 0 to zookeeper\n2014-05-29 04:44:38,344 - Changing group for /etc/zookeeper/conf/configuration.xsl from 0 to hadoop\n2014-05-29 04:44:38,344 - Directory['/var/run/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:38,345 - Directory['/var/log/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:38,346 - Directory['/hadoop/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:38,346 - Creating directory Directory['/hadoop/zookeeper']\n2014-05-29 04:44:38,347 - Changing owner for /hadoop/zookeeper from 0 to zookeeper\n2014-05-29 04:44:38,347 - Changing group for /hadoop/zookeeper from 0 to hadoop\n2014-05-29 04:44:38,348 - File['/etc/zookeeper/conf/log4j.properties'] {'content': '...', 'owner': 'zookeeper', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:38,348 - Writing File['/etc/zookeeper/conf/log4j.properties'] because contents don't match\n2014-05-29 04:44:38,349 - Changing owner for /etc/zookeeper/conf/log4j.properties from 0 to zookeeper\n2014-05-29 04:44:38,349 - Changing group for /etc/zookeeper/conf/log4j.properties from 0 to hadoop\n2014-05-29 04:44:38,350 - File['/etc/zookeeper/conf/zoo_sample.cfg'] {'owner': 'zookeeper', 'group': 'hadoop'}\n2014-05-29 04:44:38,350 - Changing owner for /etc/zookeeper/conf/zoo_sample.cfg from 0 to zookeeper\n2014-05-29 04:44:38,350 - Changing group for /etc/zookeeper/conf/zoo_sample.cfg from 0 to hadoop",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/14",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "ZOOKEEPER_SERVER INSTALL",
        "end_time" : 1401353079228,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 14,
        "request_id" : 1,
        "role" : "ZOOKEEPER_SERVER",
        "stage_id" : 1,
        "start_time" : 1401352498028,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:38,462 - Group['hadoop'] {}\n2014-05-29 04:44:38,463 - Modifying group hadoop\n2014-05-29 04:44:38,495 - Group['users'] {}\n2014-05-29 04:44:38,495 - Modifying group users\n2014-05-29 04:44:38,519 - Group['users'] {}\n2014-05-29 04:44:38,520 - Modifying group users\n2014-05-29 04:44:38,547 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:38,547 - Modifying user ambari-qa\n2014-05-29 04:44:38,569 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:38,571 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:38,587 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:38,587 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:38,587 - Modifying user yarn\n2014-05-29 04:44:38,609 - Group['nobody'] {}\n2014-05-29 04:44:38,609 - Modifying group nobody\n2014-05-29 04:44:38,634 - Group['nobody'] {}\n2014-05-29 04:44:38,634 - Modifying group nobody\n2014-05-29 04:44:38,659 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:38,659 - Modifying user nobody\n2014-05-29 04:44:38,688 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:38,688 - Modifying user nobody\n2014-05-29 04:44:38,709 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:38,710 - Modifying user hdfs\n2014-05-29 04:44:38,731 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:38,731 - Modifying user mapred\n2014-05-29 04:44:38,755 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:38,757 - Modifying user zookeeper\n2014-05-29 04:44:38,785 - Package['unzip'] {}\n2014-05-29 04:44:38,809 - Skipping installing existent package unzip\n2014-05-29 04:44:38,809 - Package['net-snmp'] {}\n2014-05-29 04:44:38,843 - Skipping installing existent package net-snmp\n2014-05-29 04:44:38,843 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:38,871 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:39,015 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:39,021 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:39,022 - Package['zookeeper'] {}\n2014-05-29 04:44:39,047 - Skipping installing existent package zookeeper\n2014-05-29 04:44:39,049 - Directory['/etc/zookeeper/conf'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:39,057 - File['/etc/zookeeper/conf/zoo.cfg'] {'owner': 'zookeeper', 'content': Template('zoo.cfg.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:39,060 - File['/etc/zookeeper/conf/zookeeper-env.sh'] {'owner': 'zookeeper', 'content': Template('zookeeper-env.sh.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:39,061 - File['/etc/zookeeper/conf/configuration.xsl'] {'owner': 'zookeeper', 'content': Template('configuration.xsl.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:39,062 - Directory['/var/run/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:39,062 - Directory['/var/log/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:39,062 - Directory['/hadoop/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:39,064 - File['/hadoop/zookeeper/myid'] {'content': '1', 'mode': 0644}\n2014-05-29 04:44:39,064 - Writing File['/hadoop/zookeeper/myid'] because it doesn't exist\n2014-05-29 04:44:39,064 - File['/etc/zookeeper/conf/log4j.properties'] {'content': '...', 'owner': 'zookeeper', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:39,065 - File['/etc/zookeeper/conf/zoo_sample.cfg'] {'owner': 'zookeeper', 'group': 'hadoop'}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/15",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "HDFS_CLIENT INSTALL",
        "end_time" : 1401353090464,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 15,
        "request_id" : 1,
        "role" : "HDFS_CLIENT",
        "stage_id" : 3,
        "start_time" : 1401353079726,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:49,501 - Group['hadoop'] {}\n2014-05-29 04:44:49,507 - Modifying group hadoop\n2014-05-29 04:44:49,541 - Group['users'] {}\n2014-05-29 04:44:49,541 - Modifying group users\n2014-05-29 04:44:49,567 - Group['users'] {}\n2014-05-29 04:44:49,567 - Modifying group users\n2014-05-29 04:44:49,595 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:49,596 - Modifying user ambari-qa\n2014-05-29 04:44:49,620 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:49,621 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:49,636 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:49,637 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:49,637 - Modifying user yarn\n2014-05-29 04:44:49,657 - Group['nobody'] {}\n2014-05-29 04:44:49,657 - Modifying group nobody\n2014-05-29 04:44:49,688 - Group['nobody'] {}\n2014-05-29 04:44:49,689 - Modifying group nobody\n2014-05-29 04:44:49,714 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:49,714 - Modifying user nobody\n2014-05-29 04:44:49,735 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:49,735 - Modifying user nobody\n2014-05-29 04:44:49,759 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:49,759 - Modifying user hdfs\n2014-05-29 04:44:49,785 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:49,786 - Modifying user mapred\n2014-05-29 04:44:49,808 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:49,808 - Modifying user zookeeper\n2014-05-29 04:44:49,827 - Package['unzip'] {}\n2014-05-29 04:44:49,861 - Skipping installing existent package unzip\n2014-05-29 04:44:49,861 - Package['net-snmp'] {}\n2014-05-29 04:44:49,888 - Skipping installing existent package net-snmp\n2014-05-29 04:44:49,889 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:49,910 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:50,027 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:50,031 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:50,033 - Package['lzo'] {}\n2014-05-29 04:44:50,055 - Skipping installing existent package lzo\n2014-05-29 04:44:50,056 - Package['hadoop'] {}\n2014-05-29 04:44:50,078 - Skipping installing existent package hadoop\n2014-05-29 04:44:50,078 - Package['hadoop-libhdfs'] {}\n2014-05-29 04:44:50,110 - Skipping installing existent package hadoop-libhdfs\n2014-05-29 04:44:50,110 - Package['hadoop-lzo'] {}\n2014-05-29 04:44:50,134 - Skipping installing existent package hadoop-lzo\n2014-05-29 04:44:50,135 - Package['hadoop-lzo-native'] {}\n2014-05-29 04:44:50,157 - Skipping installing existent package hadoop-lzo-native\n2014-05-29 04:44:50,157 - Package['snappy'] {}\n2014-05-29 04:44:50,187 - Skipping installing existent package snappy\n2014-05-29 04:44:50,187 - Package['snappy-devel'] {}\n2014-05-29 04:44:50,217 - Skipping installing existent package snappy-devel\n2014-05-29 04:44:50,218 - Package['ambari-log4j'] {}\n2014-05-29 04:44:50,254 - Skipping installing existent package ambari-log4j\n2014-05-29 04:44:50,257 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:50,266 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:44:50,267 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:44:50,269 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:44:50,271 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:50,277 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:44:50,277 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:44:50,279 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/16",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "MAPREDUCE2_CLIENT INSTALL",
        "end_time" : 1401353091321,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 16,
        "request_id" : 1,
        "role" : "MAPREDUCE2_CLIENT",
        "stage_id" : 3,
        "start_time" : 1401353079737,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:50,428 - Group['hadoop'] {}\n2014-05-29 04:44:50,429 - Modifying group hadoop\n2014-05-29 04:44:50,464 - Group['users'] {}\n2014-05-29 04:44:50,465 - Modifying group users\n2014-05-29 04:44:50,492 - Group['users'] {}\n2014-05-29 04:44:50,493 - Modifying group users\n2014-05-29 04:44:50,528 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:50,528 - Modifying user ambari-qa\n2014-05-29 04:44:50,556 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:50,558 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:50,577 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:50,577 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:50,577 - Modifying user yarn\n2014-05-29 04:44:50,605 - Group['nobody'] {}\n2014-05-29 04:44:50,605 - Modifying group nobody\n2014-05-29 04:44:50,629 - Group['nobody'] {}\n2014-05-29 04:44:50,629 - Modifying group nobody\n2014-05-29 04:44:50,654 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:50,654 - Modifying user nobody\n2014-05-29 04:44:50,679 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:50,679 - Modifying user nobody\n2014-05-29 04:44:50,702 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:50,704 - Modifying user hdfs\n2014-05-29 04:44:50,724 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:50,725 - Modifying user mapred\n2014-05-29 04:44:50,747 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:50,747 - Modifying user zookeeper\n2014-05-29 04:44:50,774 - Package['unzip'] {}\n2014-05-29 04:44:50,797 - Skipping installing existent package unzip\n2014-05-29 04:44:50,797 - Package['net-snmp'] {}\n2014-05-29 04:44:50,820 - Skipping installing existent package net-snmp\n2014-05-29 04:44:50,820 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:50,848 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:50,950 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:50,955 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:50,956 - Package['hadoop-mapreduce'] {}\n2014-05-29 04:44:50,981 - Skipping installing existent package hadoop-mapreduce\n2014-05-29 04:44:50,981 - Package['hadoop-mapreduce-historyserver'] {}\n2014-05-29 04:44:51,005 - Skipping installing existent package hadoop-mapreduce-historyserver\n2014-05-29 04:44:51,011 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:51,011 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:51,012 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:51,012 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:51,012 - Directory['/hadoop/yarn/local'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:51,012 - Directory['/hadoop/yarn/log'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:51,013 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:51,013 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:51,017 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:44:51,018 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:51,019 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:44:51,020 - XmlConfig['mapred-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:51,025 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:44:51,025 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:51,025 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:44:51,026 - XmlConfig['yarn-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:51,029 - Generating config: /etc/hadoop/conf/yarn-site.xml\n2014-05-29 04:44:51,030 - File['/etc/hadoop/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:51,030 - Writing File['/etc/hadoop/conf/yarn-site.xml'] because contents don't match\n2014-05-29 04:44:51,031 - XmlConfig['capacity-scheduler.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:51,034 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:44:51,035 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:51,035 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:44:51,036 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:44:51,038 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:51,040 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:51,044 - File['/etc/hadoop/conf/yarn-env.sh'] {'content': Template('yarn-env.sh.j2'), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/17",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "YARN_CLIENT INSTALL",
        "end_time" : 1401353093910,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 17,
        "request_id" : 1,
        "role" : "YARN_CLIENT",
        "stage_id" : 3,
        "start_time" : 1401353079744,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:52,949 - Group['hadoop'] {}\n2014-05-29 04:44:52,950 - Modifying group hadoop\n2014-05-29 04:44:52,985 - Group['users'] {}\n2014-05-29 04:44:52,985 - Modifying group users\n2014-05-29 04:44:53,013 - Group['users'] {}\n2014-05-29 04:44:53,013 - Modifying group users\n2014-05-29 04:44:53,045 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:53,045 - Modifying user ambari-qa\n2014-05-29 04:44:53,065 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:53,067 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:53,082 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:53,084 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:53,084 - Modifying user yarn\n2014-05-29 04:44:53,112 - Group['nobody'] {}\n2014-05-29 04:44:53,112 - Modifying group nobody\n2014-05-29 04:44:53,136 - Group['nobody'] {}\n2014-05-29 04:44:53,137 - Modifying group nobody\n2014-05-29 04:44:53,160 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:53,160 - Modifying user nobody\n2014-05-29 04:44:53,188 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:53,188 - Modifying user nobody\n2014-05-29 04:44:53,211 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:53,211 - Modifying user hdfs\n2014-05-29 04:44:53,232 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:53,232 - Modifying user mapred\n2014-05-29 04:44:53,258 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:53,258 - Modifying user zookeeper\n2014-05-29 04:44:53,280 - Package['unzip'] {}\n2014-05-29 04:44:53,302 - Skipping installing existent package unzip\n2014-05-29 04:44:53,302 - Package['net-snmp'] {}\n2014-05-29 04:44:53,325 - Skipping installing existent package net-snmp\n2014-05-29 04:44:53,326 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:53,352 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:53,510 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:53,516 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:53,517 - Package['hadoop-yarn'] {}\n2014-05-29 04:44:53,543 - Skipping installing existent package hadoop-yarn\n2014-05-29 04:44:53,543 - Package['hadoop-yarn-nodemanager'] {}\n2014-05-29 04:44:53,572 - Skipping installing existent package hadoop-yarn-nodemanager\n2014-05-29 04:44:53,576 - Package['hadoop-mapreduce'] {}\n2014-05-29 04:44:53,608 - Skipping installing existent package hadoop-mapreduce\n2014-05-29 04:44:53,609 - Package['hadoop-yarn-proxyserver'] {}\n2014-05-29 04:44:53,631 - Skipping installing existent package hadoop-yarn-proxyserver\n2014-05-29 04:44:53,632 - Package['hadoop-yarn-resourcemanager'] {}\n2014-05-29 04:44:53,657 - Skipping installing existent package hadoop-yarn-resourcemanager\n2014-05-29 04:44:53,660 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:53,661 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:53,661 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:53,661 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:53,662 - Directory['/hadoop/yarn/local'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:53,662 - Directory['/hadoop/yarn/log'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:53,662 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:44:53,662 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:53,667 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:44:53,668 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:53,669 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:44:53,669 - XmlConfig['mapred-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:53,677 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:44:53,678 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:53,679 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:44:53,679 - XmlConfig['yarn-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:53,682 - Generating config: /etc/hadoop/conf/yarn-site.xml\n2014-05-29 04:44:53,683 - File['/etc/hadoop/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:53,685 - Writing File['/etc/hadoop/conf/yarn-site.xml'] because contents don't match\n2014-05-29 04:44:53,685 - XmlConfig['capacity-scheduler.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:44:53,690 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:44:53,690 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:53,691 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:44:53,691 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:44:53,694 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:53,696 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}\n2014-05-29 04:44:53,700 - File['/etc/hadoop/conf/yarn-env.sh'] {'content': Template('yarn-env.sh.j2'), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/18",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "INSTALL",
        "command_detail" : "ZOOKEEPER_CLIENT INSTALL",
        "end_time" : 1401353094610,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 18,
        "request_id" : 1,
        "role" : "ZOOKEEPER_CLIENT",
        "stage_id" : 3,
        "start_time" : 1401353079755,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:44:53,834 - Group['hadoop'] {}\n2014-05-29 04:44:53,836 - Modifying group hadoop\n2014-05-29 04:44:53,868 - Group['users'] {}\n2014-05-29 04:44:53,868 - Modifying group users\n2014-05-29 04:44:53,894 - Group['users'] {}\n2014-05-29 04:44:53,894 - Modifying group users\n2014-05-29 04:44:53,922 - User['ambari-qa'] {'gid': 'hadoop', 'groups': [u'users']}\n2014-05-29 04:44:53,922 - Modifying user ambari-qa\n2014-05-29 04:44:53,944 - File['/tmp/changeUid.sh'] {'content': StaticFile('changeToSecureUid.sh'), 'mode': 0555}\n2014-05-29 04:44:53,945 - Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] {'not_if': 'test $(id -u ambari-qa) -gt 1000'}\n2014-05-29 04:44:53,959 - Skipping Execute['/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 2>/dev/null'] due to not_if\n2014-05-29 04:44:53,959 - User['yarn'] {'gid': 'hadoop'}\n2014-05-29 04:44:53,960 - Modifying user yarn\n2014-05-29 04:44:53,980 - Group['nobody'] {}\n2014-05-29 04:44:53,980 - Modifying group nobody\n2014-05-29 04:44:54,005 - Group['nobody'] {}\n2014-05-29 04:44:54,005 - Modifying group nobody\n2014-05-29 04:44:54,029 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:54,030 - Modifying user nobody\n2014-05-29 04:44:54,051 - User['nobody'] {'gid': 'hadoop', 'groups': [u'nobody']}\n2014-05-29 04:44:54,051 - Modifying user nobody\n2014-05-29 04:44:54,077 - User['hdfs'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:54,077 - Modifying user hdfs\n2014-05-29 04:44:54,102 - User['mapred'] {'gid': 'hadoop', 'groups': [u'hadoop']}\n2014-05-29 04:44:54,102 - Modifying user mapred\n2014-05-29 04:44:54,124 - User['zookeeper'] {'gid': 'hadoop'}\n2014-05-29 04:44:54,125 - Modifying user zookeeper\n2014-05-29 04:44:54,147 - Package['unzip'] {}\n2014-05-29 04:44:54,169 - Skipping installing existent package unzip\n2014-05-29 04:44:54,169 - Package['net-snmp'] {}\n2014-05-29 04:44:54,197 - Skipping installing existent package net-snmp\n2014-05-29 04:44:54,197 - Package['net-snmp-utils'] {}\n2014-05-29 04:44:54,226 - Skipping installing existent package net-snmp-utils\n2014-05-29 04:44:54,368 - Repository['HDP-2.1'] {'action': ['create'], 'mirror_list': None, 'base_url': 'http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/updates/2.1.1.0/', 'repo_file_name': 'HDP'}\n2014-05-29 04:44:54,374 - File['/etc/yum.repos.d/HDP.repo'] {'content': InlineTemplate(...)}\n2014-05-29 04:44:54,376 - Package['zookeeper'] {}\n2014-05-29 04:44:54,400 - Skipping installing existent package zookeeper\n2014-05-29 04:44:54,402 - Directory['/etc/zookeeper/conf'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:54,409 - File['/etc/zookeeper/conf/zoo.cfg'] {'owner': 'zookeeper', 'content': Template('zoo.cfg.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:54,412 - File['/etc/zookeeper/conf/zookeeper-env.sh'] {'owner': 'zookeeper', 'content': Template('zookeeper-env.sh.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:54,416 - File['/etc/zookeeper/conf/configuration.xsl'] {'owner': 'zookeeper', 'content': Template('configuration.xsl.j2'), 'group': 'hadoop'}\n2014-05-29 04:44:54,417 - Directory['/var/run/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:54,417 - Directory['/var/log/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:54,417 - Directory['/hadoop/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:44:54,418 - File['/etc/zookeeper/conf/log4j.properties'] {'content': '...', 'owner': 'zookeeper', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:44:54,418 - File['/etc/zookeeper/conf/zoo_sample.cfg'] {'owner': 'zookeeper', 'group': 'hadoop'}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/19",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "DATANODE START",
        "end_time" : 1401353109669,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 19,
        "request_id" : 1,
        "role" : "DATANODE",
        "stage_id" : 4,
        "start_time" : 1401353099818,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:45:04,929 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:45:04,931 - Writing File['/etc/snmp/snmpd.conf'] because contents don't match\n2014-05-29 04:45:04,931 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:45:04,960 - Service['snmpd'] command 'start'\n2014-05-29 04:45:05,036 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:45:05,049 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:45:05,051 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:45:05,068 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:45:05,087 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:05,089 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:05,090 - Creating directory Directory['/var/log/hadoop']\n2014-05-29 04:45:05,090 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:05,090 - Creating directory Directory['/var/run/hadoop']\n2014-05-29 04:45:05,091 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:05,091 - Changing owner for /tmp from 0 to hdfs\n2014-05-29 04:45:05,094 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:45:05,094 - Writing File['/etc/security/limits.d/hdfs.conf'] because contents don't match\n2014-05-29 04:45:05,097 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:05,098 - Writing File['/etc/hadoop/conf/taskcontroller.cfg'] because it doesn't exist\n2014-05-29 04:45:05,098 - Changing owner for /etc/hadoop/conf/taskcontroller.cfg from 0 to hdfs\n2014-05-29 04:45:05,109 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:05,109 - Writing File['/etc/hadoop/conf/hadoop-env.sh'] because contents don't match\n2014-05-29 04:45:05,110 - Changing owner for /etc/hadoop/conf/hadoop-env.sh from 0 to hdfs\n2014-05-29 04:45:05,111 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:05,112 - Writing File['/etc/hadoop/conf/commons-logging.properties'] because it doesn't exist\n2014-05-29 04:45:05,112 - Changing owner for /etc/hadoop/conf/commons-logging.properties from 0 to hdfs\n2014-05-29 04:45:05,114 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:05,115 - Writing File['/etc/hadoop/conf/slaves'] because contents don't match\n2014-05-29 04:45:05,115 - Changing owner for /etc/hadoop/conf/slaves from 0 to hdfs\n2014-05-29 04:45:05,117 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:05,118 - Writing File['/etc/hadoop/conf/health_check'] because it doesn't exist\n2014-05-29 04:45:05,118 - Changing owner for /etc/hadoop/conf/health_check from 0 to hdfs\n2014-05-29 04:45:05,118 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:45:05,118 - Writing File['/etc/hadoop/conf/log4j.properties'] because contents don't match\n2014-05-29 04:45:05,119 - Changing owner for /etc/hadoop/conf/log4j.properties from 0 to hdfs\n2014-05-29 04:45:05,119 - Changing group for /etc/hadoop/conf/log4j.properties from 0 to hadoop\n2014-05-29 04:45:05,122 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:05,124 - Writing File['/etc/hadoop/conf/hadoop-metrics2.properties'] because contents don't match\n2014-05-29 04:45:05,124 - Changing owner for /etc/hadoop/conf/hadoop-metrics2.properties from 0 to hdfs\n2014-05-29 04:45:05,124 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:05,129 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:45:05,129 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:05,130 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because it doesn't exist\n2014-05-29 04:45:05,130 - Changing owner for /etc/hadoop/conf/mapred-queue-acls.xml from 0 to mapred\n2014-05-29 04:45:05,130 - Changing group for /etc/hadoop/conf/mapred-queue-acls.xml from 0 to hadoop\n2014-05-29 04:45:05,130 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:05,135 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:45:05,135 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:05,136 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:45:05,136 - Changing owner for /etc/hadoop/conf/hadoop-policy.xml from 0 to hdfs\n2014-05-29 04:45:05,136 - Changing group for /etc/hadoop/conf/hadoop-policy.xml from 0 to hadoop\n2014-05-29 04:45:05,136 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:05,139 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:45:05,139 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:05,140 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:45:05,140 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:05,143 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:45:05,143 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:05,144 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:45:05,145 - Changing owner for /etc/hadoop/conf/mapred-site.xml from 1002 to mapred\n2014-05-29 04:45:05,145 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:45:05,146 - Writing File['/etc/hadoop/conf/task-log4j.properties'] because it doesn't exist\n2014-05-29 04:45:05,146 - Changing permission for /etc/hadoop/conf/task-log4j.properties from 644 to 755\n2014-05-29 04:45:05,146 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:05,149 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:45:05,149 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:05,150 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:45:05,150 - Changing owner for /etc/hadoop/conf/capacity-scheduler.xml from 1002 to hdfs\n2014-05-29 04:45:05,150 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:05,154 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:45:05,154 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:05,155 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:45:05,155 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:45:05,155 - Changing owner for /etc/hadoop/conf/configuration.xsl from 0 to hdfs\n2014-05-29 04:45:05,156 - Changing group for /etc/hadoop/conf/configuration.xsl from 0 to hadoop\n2014-05-29 04:45:05,156 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:05,156 - Changing owner for /etc/hadoop/conf/ssl-client.xml.example from 0 to mapred\n2014-05-29 04:45:05,156 - Changing group for /etc/hadoop/conf/ssl-client.xml.example from 0 to hadoop\n2014-05-29 04:45:05,156 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:05,157 - Changing owner for /etc/hadoop/conf/ssl-server.xml.example from 0 to mapred\n2014-05-29 04:45:05,157 - Changing group for /etc/hadoop/conf/ssl-server.xml.example from 0 to hadoop\n2014-05-29 04:45:05,286 - Directory['/var/lib/hadoop-hdfs'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0751, 'recursive': True}\n2014-05-29 04:45:05,287 - Changing permission for /var/lib/hadoop-hdfs from 755 to 751\n2014-05-29 04:45:05,287 - Directory['/hadoop/hdfs/data'] {'owner': 'hdfs', 'ignore_failures': True, 'group': 'hadoop', 'mode': 0755, 'recursive': True}\n2014-05-29 04:45:05,288 - Creating directory Directory['/hadoop/hdfs/data']\n2014-05-29 04:45:05,288 - Changing owner for /hadoop/hdfs/data from 0 to hdfs\n2014-05-29 04:45:05,288 - Changing group for /hadoop/hdfs/data from 0 to hadoop\n2014-05-29 04:45:05,289 - Directory['/var/run/hadoop/hdfs'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:05,289 - Creating directory Directory['/var/run/hadoop/hdfs']\n2014-05-29 04:45:05,290 - Changing owner for /var/run/hadoop/hdfs from 0 to hdfs\n2014-05-29 04:45:05,290 - Directory['/var/log/hadoop/hdfs'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:05,290 - Creating directory Directory['/var/log/hadoop/hdfs']\n2014-05-29 04:45:05,290 - Changing owner for /var/log/hadoop/hdfs from 0 to hdfs\n2014-05-29 04:45:05,290 - File['/var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid'] {'action': ['delete'], 'not_if': 'ls /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid` >/dev/null 2>&1', 'ignore_failures': True}\n2014-05-29 04:45:05,315 - Execute['ulimit -c unlimited;  export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode'] {'not_if': 'ls /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid` >/dev/null 2>&1', 'user': 'hdfs'}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/20",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "GANGLIA_MONITOR START",
        "end_time" : 1401353111102,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 20,
        "request_id" : 1,
        "role" : "GANGLIA_MONITOR",
        "stage_id" : 4,
        "start_time" : 1401353099826,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:45:09,597 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:45:09,599 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:45:09,618 - Service['snmpd'] command 'restart'\n2014-05-29 04:45:09,794 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:45:09,807 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:45:09,808 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:45:09,824 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:45:09,840 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:09,840 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:09,841 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:09,841 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:09,843 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:45:09,845 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:09,852 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:09,854 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:09,856 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:09,858 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:09,859 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:45:09,864 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:09,865 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:09,870 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:45:09,870 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:09,871 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because contents don't match\n2014-05-29 04:45:09,871 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:09,875 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:45:09,876 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:09,877 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:45:09,877 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:09,881 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:45:09,882 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:09,883 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:45:09,884 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:09,887 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:45:09,887 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:09,888 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:45:09,889 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:45:09,889 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:09,892 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:45:09,892 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:09,894 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:45:09,894 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:09,897 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:45:09,897 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:09,898 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:45:09,899 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:45:09,899 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:09,900 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:10,023 - Directory['/etc/ganglia/hdp'] {'owner': 'root', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:45:10,025 - Directory['/usr/libexec/hdp/ganglia'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:10,025 - File['/etc/init.d/hdp-gmetad'] {'content': StaticFile('gmetad.init'), 'mode': 0755}\n2014-05-29 04:45:10,025 - File['/etc/init.d/hdp-gmond'] {'content': StaticFile('gmond.init'), 'mode': 0755}\n2014-05-29 04:45:10,026 - File['/usr/libexec/hdp/ganglia/checkGmond.sh'] {'content': StaticFile('checkGmond.sh'), 'mode': 0755}\n2014-05-29 04:45:10,026 - File['/usr/libexec/hdp/ganglia/checkRrdcached.sh'] {'content': StaticFile('checkRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:45:10,026 - File['/usr/libexec/hdp/ganglia/gmetadLib.sh'] {'content': StaticFile('gmetadLib.sh'), 'mode': 0755}\n2014-05-29 04:45:10,026 - File['/usr/libexec/hdp/ganglia/gmondLib.sh'] {'content': StaticFile('gmondLib.sh'), 'mode': 0755}\n2014-05-29 04:45:10,027 - File['/usr/libexec/hdp/ganglia/rrdcachedLib.sh'] {'content': StaticFile('rrdcachedLib.sh'), 'mode': 0755}\n2014-05-29 04:45:10,027 - File['/usr/libexec/hdp/ganglia/setupGanglia.sh'] {'content': StaticFile('setupGanglia.sh'), 'mode': 0755}\n2014-05-29 04:45:10,027 - File['/usr/libexec/hdp/ganglia/startGmetad.sh'] {'content': StaticFile('startGmetad.sh'), 'mode': 0755}\n2014-05-29 04:45:10,028 - File['/usr/libexec/hdp/ganglia/startGmond.sh'] {'content': StaticFile('startGmond.sh'), 'mode': 0755}\n2014-05-29 04:45:10,028 - File['/usr/libexec/hdp/ganglia/startRrdcached.sh'] {'content': StaticFile('startRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:45:10,028 - File['/usr/libexec/hdp/ganglia/stopGmetad.sh'] {'content': StaticFile('stopGmetad.sh'), 'mode': 0755}\n2014-05-29 04:45:10,029 - File['/usr/libexec/hdp/ganglia/stopGmond.sh'] {'content': StaticFile('stopGmond.sh'), 'mode': 0755}\n2014-05-29 04:45:10,029 - File['/usr/libexec/hdp/ganglia/stopRrdcached.sh'] {'content': StaticFile('stopRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:45:10,029 - File['/usr/libexec/hdp/ganglia/teardownGanglia.sh'] {'content': StaticFile('teardownGanglia.sh'), 'mode': 0755}\n2014-05-29 04:45:10,030 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:10,036 - File['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] {'content': Template('gangliaClusters.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:10,037 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:10,039 - File['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] {'content': Template('gangliaEnv.sh.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:10,041 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaLib.sh'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:10,045 - File['/usr/libexec/hdp/ganglia/gangliaLib.sh'] {'content': Template('gangliaLib.sh.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:10,045 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPNameNode -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,104 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPResourceManager -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,151 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPHistoryServer -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,206 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPSlaves -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,279 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPDataNode -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,346 - Directory['/etc/ganglia/conf.d'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:45:10,347 - File['/etc/ganglia/conf.d/modgstatus.conf'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:45:10,348 - File['/etc/ganglia/conf.d/multicpu.conf'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:45:10,348 - File['/etc/ganglia/gmond.conf'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:45:10,349 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPNameNode -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,396 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPResourceManager -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,460 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPNodeManager -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,517 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPHistoryServer -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,568 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPDataNode -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,627 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -c HDPSlaves -m -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:10,681 - Execute['service hdp-gmond start >> /tmp/gmond.log  2>&1 ; /bin/ps auwx | /bin/grep [g]mond  >> /tmp/gmond.log  2>&1'] {'path': ['/usr/sbin:/sbin:/usr/local/bin:/bin:/usr/bin']}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/21",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "GANGLIA_SERVER START",
        "end_time" : 1401353112352,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 21,
        "request_id" : 1,
        "role" : "GANGLIA_SERVER",
        "stage_id" : 4,
        "start_time" : 1401353099834,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:45:11,035 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:45:11,037 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:45:11,068 - Service['snmpd'] command 'restart'\n2014-05-29 04:45:11,277 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:45:11,297 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:45:11,299 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:45:11,324 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:45:11,346 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:11,347 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:11,347 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:11,348 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:11,350 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:45:11,352 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:11,362 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:11,364 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:11,366 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:11,368 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:11,368 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:45:11,372 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:11,374 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:11,379 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:45:11,380 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:11,381 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because contents don't match\n2014-05-29 04:45:11,382 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:11,384 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:45:11,385 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:11,385 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:45:11,385 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:11,388 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:45:11,389 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:11,389 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:45:11,390 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:11,394 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:45:11,394 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:11,395 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:45:11,395 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:45:11,396 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:11,399 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:45:11,400 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:11,400 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:45:11,402 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:11,405 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:45:11,405 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:11,406 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:45:11,407 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:45:11,407 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:11,408 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:11,521 - Directory['/usr/libexec/hdp/ganglia'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:11,522 - File['/etc/init.d/hdp-gmetad'] {'content': StaticFile('gmetad.init'), 'mode': 0755}\n2014-05-29 04:45:11,522 - File['/etc/init.d/hdp-gmond'] {'content': StaticFile('gmond.init'), 'mode': 0755}\n2014-05-29 04:45:11,524 - File['/usr/libexec/hdp/ganglia/checkGmond.sh'] {'content': StaticFile('checkGmond.sh'), 'mode': 0755}\n2014-05-29 04:45:11,525 - File['/usr/libexec/hdp/ganglia/checkRrdcached.sh'] {'content': StaticFile('checkRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:45:11,525 - File['/usr/libexec/hdp/ganglia/gmetadLib.sh'] {'content': StaticFile('gmetadLib.sh'), 'mode': 0755}\n2014-05-29 04:45:11,526 - File['/usr/libexec/hdp/ganglia/gmondLib.sh'] {'content': StaticFile('gmondLib.sh'), 'mode': 0755}\n2014-05-29 04:45:11,526 - File['/usr/libexec/hdp/ganglia/rrdcachedLib.sh'] {'content': StaticFile('rrdcachedLib.sh'), 'mode': 0755}\n2014-05-29 04:45:11,527 - File['/usr/libexec/hdp/ganglia/setupGanglia.sh'] {'content': StaticFile('setupGanglia.sh'), 'mode': 0755}\n2014-05-29 04:45:11,527 - File['/usr/libexec/hdp/ganglia/startGmetad.sh'] {'content': StaticFile('startGmetad.sh'), 'mode': 0755}\n2014-05-29 04:45:11,527 - File['/usr/libexec/hdp/ganglia/startGmond.sh'] {'content': StaticFile('startGmond.sh'), 'mode': 0755}\n2014-05-29 04:45:11,527 - File['/usr/libexec/hdp/ganglia/startRrdcached.sh'] {'content': StaticFile('startRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:45:11,528 - File['/usr/libexec/hdp/ganglia/stopGmetad.sh'] {'content': StaticFile('stopGmetad.sh'), 'mode': 0755}\n2014-05-29 04:45:11,529 - File['/usr/libexec/hdp/ganglia/stopGmond.sh'] {'content': StaticFile('stopGmond.sh'), 'mode': 0755}\n2014-05-29 04:45:11,529 - File['/usr/libexec/hdp/ganglia/stopRrdcached.sh'] {'content': StaticFile('stopRrdcached.sh'), 'mode': 0755}\n2014-05-29 04:45:11,529 - File['/usr/libexec/hdp/ganglia/teardownGanglia.sh'] {'content': StaticFile('teardownGanglia.sh'), 'mode': 0755}\n2014-05-29 04:45:11,530 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:11,544 - File['/usr/libexec/hdp/ganglia/gangliaClusters.conf'] {'content': Template('gangliaClusters.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:11,545 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:11,548 - File['/usr/libexec/hdp/ganglia/gangliaEnv.sh'] {'content': Template('gangliaEnv.sh.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:11,549 - TemplateConfig['/usr/libexec/hdp/ganglia/gangliaLib.sh'] {'owner': 'root', 'template_tag': None, 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:11,553 - File['/usr/libexec/hdp/ganglia/gangliaLib.sh'] {'content': Template('gangliaLib.sh.j2'), 'owner': 'root', 'group': 'root', 'mode': 0755}\n2014-05-29 04:45:11,555 - Execute['/usr/libexec/hdp/ganglia/setupGanglia.sh -t -o root -g hadoop'] {'path': ['/usr/libexec/hdp/ganglia', '/usr/sbin', '/sbin:/usr/local/bin', '/bin', '/usr/bin']}\n2014-05-29 04:45:11,625 - Directory['/var/lib/ganglia/dwoo'] {'owner': 'nobody', 'recursive': True, 'mode': 0777}\n2014-05-29 04:45:11,625 - Directory['/var/www/cgi-bin'] {'recursive': True}\n2014-05-29 04:45:11,626 - File['/var/www/cgi-bin/rrd.py'] {'content': StaticFile('rrd.py'), 'mode': 0755}\n2014-05-29 04:45:11,627 - File['/etc/ganglia/gmetad.conf'] {'owner': 'root', 'group': 'hadoop'}\n2014-05-29 04:45:11,627 - Execute['service hdp-gmetad start >> /tmp/gmetad.log  2>&1 ; /bin/ps auwx | /bin/grep [g]metad  >> /tmp/gmetad.log  2>&1'] {'path': ['/usr/sbin:/sbin:/usr/local/bin:/bin:/usr/bin']}\n2014-05-29 04:45:11,846 - MonitorWebserver['restart'] {}\n2014-05-29 04:45:11,850 - Execute['/etc/init.d/httpd stop'] {}\n2014-05-29 04:45:11,902 - Execute['grep -E 'KeepAlive (On|Off)' /etc/httpd/conf/httpd.conf && sed -i 's/KeepAlive Off/KeepAlive On/' /etc/httpd/conf/httpd.conf || echo 'KeepAlive On' >> /etc/httpd/conf/httpd.conf'] {}\n2014-05-29 04:45:11,948 - Execute['/etc/init.d/httpd start'] {}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/22",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "NAMENODE START",
        "end_time" : 1401353155478,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 22,
        "request_id" : 1,
        "role" : "NAMENODE",
        "stage_id" : 4,
        "start_time" : 1401353099842,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:45:12,197 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:45:12,200 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:45:12,243 - Service['snmpd'] command 'restart'\n2014-05-29 04:45:12,471 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:45:12,491 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:45:12,492 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:45:12,514 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:45:12,538 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:12,539 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:12,540 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:12,541 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:12,552 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:45:12,555 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:12,564 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:12,568 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:12,570 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:12,572 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:12,574 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:45:12,577 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:12,579 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:12,584 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:45:12,585 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:12,585 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because contents don't match\n2014-05-29 04:45:12,586 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:12,589 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:45:12,589 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:12,590 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:45:12,590 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:12,594 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:45:12,595 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:12,596 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:45:12,596 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:12,599 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:45:12,600 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:12,601 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:45:12,601 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:45:12,602 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:12,605 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:45:12,606 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:12,607 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:45:12,607 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:12,611 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:45:12,611 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:12,612 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:45:12,614 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:45:12,614 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:12,615 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:12,758 - Directory['/hadoop/hdfs/namenode'] {'owner': 'hdfs', 'group': 'hadoop', 'recursive': True, 'mode': 0755}\n2014-05-29 04:45:12,759 - File['/tmp/checkForFormat.sh'] {'content': StaticFile('checkForFormat.sh'), 'mode': 0755}\n2014-05-29 04:45:12,769 - Writing File['/tmp/checkForFormat.sh'] because it doesn't exist\n2014-05-29 04:45:12,770 - Changing permission for /tmp/checkForFormat.sh from 644 to 755\n2014-05-29 04:45:12,770 - Execute['sh /tmp/checkForFormat.sh hdfs /etc/hadoop/conf /var/run/hadoop/hdfs/namenode/formatted/ /hadoop/hdfs/namenode'] {'path': ['/usr/sbin:/sbin:/usr/local/bin:/bin:/usr/bin'], 'not_if': 'test -d /var/run/hadoop/hdfs/namenode/formatted/'}\n2014-05-29 04:45:16,667 - Execute['mkdir -p /var/run/hadoop/hdfs/namenode/formatted/'] {}\n2014-05-29 04:45:16,702 - File['/etc/hadoop/conf/dfs.exclude'] {'owner': 'hdfs', 'content': Template('exclude_hosts_list.j2'), 'group': 'hadoop'}\n2014-05-29 04:45:16,703 - Writing File['/etc/hadoop/conf/dfs.exclude'] because it doesn't exist\n2014-05-29 04:45:16,703 - Changing owner for /etc/hadoop/conf/dfs.exclude from 0 to hdfs\n2014-05-29 04:45:16,704 - Changing group for /etc/hadoop/conf/dfs.exclude from 0 to hadoop\n2014-05-29 04:45:16,705 - Directory['/var/run/hadoop/hdfs'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:16,705 - Directory['/var/log/hadoop/hdfs'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:16,706 - File['/var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid'] {'action': ['delete'], 'not_if': 'ls /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid` >/dev/null 2>&1', 'ignore_failures': True}\n2014-05-29 04:45:16,727 - Execute['ulimit -c unlimited;  export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start namenode'] {'not_if': 'ls /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid` >/dev/null 2>&1', 'user': 'hdfs'}\n2014-05-29 04:45:20,927 - Execute['su - hdfs -c 'hadoop dfsadmin -safemode get' | grep 'Safe mode is OFF''] {'tries': 40, 'only_if': None, 'try_sleep': 10}\n2014-05-29 04:45:27,304 - HdfsDirectory['/tmp'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'mode': 0777, 'owner': 'hdfs', 'action': ['create_delayed']}\n2014-05-29 04:45:27,306 - HdfsDirectory['/user/ambari-qa'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'mode': 0770, 'owner': 'ambari-qa', 'action': ['create_delayed']}\n2014-05-29 04:45:27,307 - HdfsDirectory['None'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'action': ['create'], 'only_if': None}\n2014-05-29 04:45:27,308 - Execute['hadoop fs -mkdir `rpm -q hadoop | grep -q \"hadoop-1\" || echo \"-p\"` /tmp /user/ambari-qa && hadoop fs -chmod  777 /tmp && hadoop fs -chmod  770 /user/ambari-qa && hadoop fs -chown  hdfs /tmp && hadoop fs -chown  ambari-qa /user/ambari-qa'] {'not_if': \"su - hdfs -c 'hadoop fs -ls /tmp /user/ambari-qa'\", 'user': 'hdfs'}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/23",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "ZOOKEEPER_SERVER START",
        "end_time" : 1401353159237,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 23,
        "request_id" : 1,
        "role" : "ZOOKEEPER_SERVER",
        "stage_id" : 4,
        "start_time" : 1401353099850,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:45:57,280 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:45:57,285 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:45:57,309 - Service['snmpd'] command 'restart'\n2014-05-29 04:45:57,522 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:45:57,540 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:45:57,542 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:45:57,569 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:45:57,592 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:57,593 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:57,594 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:45:57,594 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:45:57,596 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:45:57,599 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:57,607 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:57,608 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:57,611 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:57,614 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:57,614 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:45:57,620 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:45:57,621 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:57,629 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:45:57,629 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:57,630 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because contents don't match\n2014-05-29 04:45:57,631 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:57,636 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:45:57,637 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:57,638 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:45:57,638 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:57,641 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:45:57,641 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:57,642 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:45:57,642 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:57,647 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:45:57,648 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:57,649 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:45:57,650 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:45:57,650 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:57,655 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:45:57,656 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:57,657 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:45:57,657 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:45:57,662 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:45:57,662 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:45:57,665 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:45:57,666 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:45:57,667 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:57,667 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:45:57,776 - Directory['/etc/zookeeper/conf'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:45:57,790 - File['/etc/zookeeper/conf/zoo.cfg'] {'owner': 'zookeeper', 'content': Template('zoo.cfg.j2'), 'group': 'hadoop'}\n2014-05-29 04:45:57,794 - File['/etc/zookeeper/conf/zookeeper-env.sh'] {'owner': 'zookeeper', 'content': Template('zookeeper-env.sh.j2'), 'group': 'hadoop'}\n2014-05-29 04:45:57,796 - File['/etc/zookeeper/conf/configuration.xsl'] {'owner': 'zookeeper', 'content': Template('configuration.xsl.j2'), 'group': 'hadoop'}\n2014-05-29 04:45:57,796 - Directory['/var/run/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:45:57,796 - Directory['/var/log/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:45:57,797 - Directory['/hadoop/zookeeper'] {'owner': 'zookeeper', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:45:57,797 - File['/hadoop/zookeeper/myid'] {'content': '1', 'mode': 0644}\n2014-05-29 04:45:57,798 - File['/etc/zookeeper/conf/log4j.properties'] {'content': '...', 'owner': 'zookeeper', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:45:57,798 - File['/etc/zookeeper/conf/zoo_sample.cfg'] {'owner': 'zookeeper', 'group': 'hadoop'}\n2014-05-29 04:45:57,799 - Execute['source /etc/zookeeper/conf/zookeeper-env.sh ; env ZOOCFGDIR=/etc/zookeeper/conf ZOOCFG=zoo.cfg /usr/lib/zookeeper/bin/zkServer.sh start'] {'not_if': 'ls /var/run/zookeeper/zookeeper_server.pid >/dev/null 2>&1 && ps `cat /var/run/zookeeper/zookeeper_server.pid` >/dev/null 2>&1', 'user': 'zookeeper'}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/24",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "HISTORYSERVER START",
        "end_time" : 1401353219918,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 24,
        "request_id" : 1,
        "role" : "HISTORYSERVER",
        "stage_id" : 5,
        "start_time" : 1401353160111,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:46:09,531 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:46:09,537 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:46:09,577 - Service['snmpd'] command 'restart'\n2014-05-29 04:46:09,791 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:46:09,810 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:46:09,811 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:46:09,847 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:46:09,873 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:46:09,874 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:46:09,874 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:46:09,874 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:46:09,876 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:46:09,876 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:46:09,887 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:46:09,888 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:46:09,891 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:46:09,893 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:46:09,893 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:46:09,898 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:46:09,899 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:09,905 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:46:09,905 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:46:09,905 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because contents don't match\n2014-05-29 04:46:09,906 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:09,910 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:46:09,910 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:46:09,911 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:46:09,911 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:09,915 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:46:09,916 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:46:09,917 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:46:09,919 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:09,925 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:46:09,927 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:46:09,928 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:46:09,929 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:46:09,930 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:09,936 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:46:09,937 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:46:09,938 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:46:09,938 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:09,942 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:46:09,943 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:46:09,944 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:46:09,945 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:46:09,945 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:46:09,946 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:46:10,118 - HdfsDirectory['/app-logs'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'recursive_chmod': True, 'owner': 'yarn', 'group': 'hadoop', 'action': ['create_delayed'], 'mode': 0777}\n2014-05-29 04:46:10,120 - HdfsDirectory['/mapred'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'owner': 'mapred', 'action': ['create_delayed']}\n2014-05-29 04:46:10,120 - HdfsDirectory['/mapred/system'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'owner': 'hdfs', 'action': ['create_delayed']}\n2014-05-29 04:46:10,120 - HdfsDirectory['/mr-history/tmp'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'mode': 0777, 'owner': 'mapred', 'group': 'hadoop', 'action': ['create_delayed']}\n2014-05-29 04:46:10,120 - HdfsDirectory['/mr-history/done'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'mode': 01777, 'owner': 'mapred', 'group': 'hadoop', 'action': ['create_delayed']}\n2014-05-29 04:46:10,120 - HdfsDirectory['None'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'action': ['create']}\n2014-05-29 04:46:10,122 - Execute['hadoop fs -mkdir `rpm -q hadoop | grep -q \"hadoop-1\" || echo \"-p\"` /app-logs /mapred /mapred/system /mr-history/tmp /mr-history/done && hadoop fs -chmod -R 777 /app-logs && hadoop fs -chmod  777 /mr-history/tmp && hadoop fs -chmod  1777 /mr-history/done && hadoop fs -chown  mapred /mapred && hadoop fs -chown  hdfs /mapred/system && hadoop fs -chown  yarn:hadoop /app-logs && hadoop fs -chown  mapred:hadoop /mr-history/tmp /mr-history/done'] {'not_if': \"su - hdfs -c 'hadoop fs -ls /app-logs /mapred /mapred/system /mr-history/tmp /mr-history/done'\", 'user': 'hdfs'}\n2014-05-29 04:46:53,525 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:46:53,526 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:46:53,527 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:46:53,527 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:46:53,528 - Directory['/hadoop/yarn/local'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:46:53,528 - Directory['/hadoop/yarn/log'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:46:53,528 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:46:53,528 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:53,534 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:46:53,535 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:46:53,536 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:46:53,537 - XmlConfig['mapred-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:53,539 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:46:53,541 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:46:53,542 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:46:53,542 - Changing owner for /etc/hadoop/conf/mapred-site.xml from 1004 to yarn\n2014-05-29 04:46:53,542 - XmlConfig['yarn-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:53,545 - Generating config: /etc/hadoop/conf/yarn-site.xml\n2014-05-29 04:46:53,547 - File['/etc/hadoop/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:46:53,548 - Writing File['/etc/hadoop/conf/yarn-site.xml'] because contents don't match\n2014-05-29 04:46:53,548 - XmlConfig['capacity-scheduler.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:46:53,552 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:46:53,555 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:46:53,556 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:46:53,557 - Changing owner for /etc/hadoop/conf/capacity-scheduler.xml from 1003 to yarn\n2014-05-29 04:46:53,557 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:46:53,561 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}\n2014-05-29 04:46:53,564 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}\n2014-05-29 04:46:53,571 - File['/etc/hadoop/conf/yarn-env.sh'] {'content': Template('yarn-env.sh.j2'), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}\n2014-05-29 04:46:53,573 - Execute['export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop-mapreduce/sbin/mr-jobhistory-daemon.sh --config /etc/hadoop/conf start historyserver'] {'not_if': 'ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid` >/dev/null 2>&1', 'user': 'mapred'}\n2014-05-29 04:46:54,754 - Execute['ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid` >/dev/null 2>&1'] {'initial_wait': 5, 'not_if': 'ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid` >/dev/null 2>&1', 'user': 'mapred'}\n2014-05-29 04:46:59,789 - Skipping Execute['ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid` >/dev/null 2>&1'] due to not_if",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/25",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "RESOURCEMANAGER START",
        "end_time" : 1401353228980,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 25,
        "request_id" : 1,
        "role" : "RESOURCEMANAGER",
        "stage_id" : 5,
        "start_time" : 1401353160125,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:47:01,686 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:47:01,688 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:47:01,718 - Service['snmpd'] command 'restart'\n2014-05-29 04:47:01,908 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:47:01,928 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:47:01,930 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:47:01,953 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:47:01,977 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:01,978 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:01,978 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:01,979 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:47:01,980 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:47:01,984 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:01,992 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:01,994 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:01,996 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:01,997 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:01,998 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:02,003 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:02,004 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,009 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:47:02,009 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:02,010 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because contents don't match\n2014-05-29 04:47:02,010 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,013 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:47:02,014 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:02,014 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:47:02,015 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,018 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:47:02,018 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:02,019 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:47:02,020 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,024 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:47:02,024 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:02,025 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:47:02,025 - Changing owner for /etc/hadoop/conf/mapred-site.xml from 1002 to mapred\n2014-05-29 04:47:02,026 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:47:02,027 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,030 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:47:02,031 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:02,031 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:47:02,032 - Changing owner for /etc/hadoop/conf/capacity-scheduler.xml from 1002 to hdfs\n2014-05-29 04:47:02,032 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,036 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:47:02,036 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:02,037 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:47:02,037 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:47:02,038 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:47:02,039 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:47:02,149 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:47:02,150 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:47:02,151 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:47:02,151 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:47:02,151 - Directory['/hadoop/yarn/local'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:47:02,152 - Directory['/hadoop/yarn/log'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:47:02,152 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:47:02,152 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,160 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:47:02,161 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:02,162 - XmlConfig['mapred-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,165 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:47:02,166 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:02,167 - Changing owner for /etc/hadoop/conf/mapred-site.xml from 1004 to yarn\n2014-05-29 04:47:02,167 - XmlConfig['yarn-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,170 - Generating config: /etc/hadoop/conf/yarn-site.xml\n2014-05-29 04:47:02,170 - File['/etc/hadoop/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:02,171 - Writing File['/etc/hadoop/conf/yarn-site.xml'] because contents don't match\n2014-05-29 04:47:02,171 - XmlConfig['capacity-scheduler.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:02,176 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:47:02,176 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:02,177 - Changing owner for /etc/hadoop/conf/capacity-scheduler.xml from 1003 to yarn\n2014-05-29 04:47:02,177 - File['/var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:47:02,178 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:47:02,181 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}\n2014-05-29 04:47:02,186 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}\n2014-05-29 04:47:02,189 - File['/etc/hadoop/conf/yarn-env.sh'] {'content': Template('yarn-env.sh.j2'), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}\n2014-05-29 04:47:02,190 - Execute['export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start resourcemanager'] {'not_if': 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid` >/dev/null 2>&1', 'user': 'yarn'}\n2014-05-29 04:47:03,401 - Execute['ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid` >/dev/null 2>&1'] {'initial_wait': 5, 'not_if': 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid` >/dev/null 2>&1', 'user': 'yarn'}\n2014-05-29 04:47:08,515 - Skipping Execute['ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid` >/dev/null 2>&1'] due to not_if",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/26",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "SECONDARY_NAMENODE START",
        "end_time" : 1401353234475,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 26,
        "request_id" : 1,
        "role" : "SECONDARY_NAMENODE",
        "stage_id" : 5,
        "start_time" : 1401353160147,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:47:09,060 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:47:09,083 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:47:09,269 - Service['snmpd'] command 'restart'\n2014-05-29 04:47:09,528 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:47:09,603 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:47:09,604 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:47:09,662 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:47:09,695 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:09,697 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:09,698 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:09,698 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:47:09,701 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:47:09,704 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:09,715 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:09,717 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:09,720 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:09,723 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:09,724 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:09,729 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:09,729 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:09,736 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:47:09,737 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:09,737 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because contents don't match\n2014-05-29 04:47:09,739 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:09,744 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:47:09,744 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:09,745 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:47:09,746 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:09,748 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:47:09,749 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:09,750 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:47:09,750 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:09,755 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:47:09,756 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:09,757 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:47:09,757 - Changing owner for /etc/hadoop/conf/mapred-site.xml from 1002 to mapred\n2014-05-29 04:47:09,757 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:47:09,758 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:09,760 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:47:09,761 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:09,761 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:47:09,762 - Changing owner for /etc/hadoop/conf/capacity-scheduler.xml from 1002 to hdfs\n2014-05-29 04:47:09,764 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:09,768 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:47:09,769 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:09,771 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:47:09,771 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:47:09,771 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:47:09,773 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:47:09,915 - Directory['/hadoop/hdfs/namesecondary'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0755, 'recursive': True}\n2014-05-29 04:47:09,917 - Creating directory Directory['/hadoop/hdfs/namesecondary']\n2014-05-29 04:47:09,918 - Changing owner for /hadoop/hdfs/namesecondary from 0 to hdfs\n2014-05-29 04:47:09,918 - Changing group for /hadoop/hdfs/namesecondary from 0 to hadoop\n2014-05-29 04:47:09,920 - Directory['/var/run/hadoop/hdfs'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:47:09,920 - Directory['/var/log/hadoop/hdfs'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:47:09,921 - File['/var/run/hadoop/hdfs/hadoop-hdfs-secondarynamenode.pid'] {'action': ['delete'], 'not_if': 'ls /var/run/hadoop/hdfs/hadoop-hdfs-secondarynamenode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-secondarynamenode.pid` >/dev/null 2>&1', 'ignore_failures': True}\n2014-05-29 04:47:09,948 - Execute['ulimit -c unlimited;  export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start secondarynamenode'] {'not_if': 'ls /var/run/hadoop/hdfs/hadoop-hdfs-secondarynamenode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-secondarynamenode.pid` >/dev/null 2>&1', 'user': 'hdfs'}",
        "structured_out" : "{}"
      }
    },
    {
      "href" : "http://172.18.0.2:8080/api/v1/clusters/MySingleNodeCluster/requests/1/tasks/27",
      "Tasks" : {
        "attempt_cnt" : 1,
        "cluster_name" : "MySingleNodeCluster",
        "command" : "START",
        "command_detail" : "NODEMANAGER START",
        "end_time" : 1401353256892,
        "exit_code" : 0,
        "host_name" : "server.ambari.com",
        "id" : 27,
        "request_id" : 1,
        "role" : "NODEMANAGER",
        "stage_id" : 6,
        "start_time" : 1401353240600,
        "status" : "COMPLETED",
        "stderr" : "None",
        "stdout" : "2014-05-29 04:47:24,708 - File['/etc/snmp/snmpd.conf'] {'content': Template('snmpd.conf.j2')}\n2014-05-29 04:47:24,710 - Service['snmpd'] {'action': ['restart']}\n2014-05-29 04:47:24,739 - Service['snmpd'] command 'restart'\n2014-05-29 04:47:24,939 - Execute['/bin/echo 0 > /selinux/enforce'] {'only_if': 'test -f /selinux/enforce'}\n2014-05-29 04:47:24,959 - Skipping Execute['/bin/echo 0 > /selinux/enforce'] due to only_if\n2014-05-29 04:47:24,961 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-i386-32; ln -sf /usr/lib/libsnappy.so /usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so'] {}\n2014-05-29 04:47:24,984 - Execute['mkdir -p /usr/lib/hadoop/lib/native/Linux-amd64-64; ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so'] {}\n2014-05-29 04:47:25,012 - Directory['/etc/hadoop/conf'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:25,014 - Directory['/var/log/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:25,015 - Directory['/var/run/hadoop'] {'owner': 'root', 'group': 'root', 'recursive': True}\n2014-05-29 04:47:25,016 - Directory['/tmp'] {'owner': 'hdfs', 'recursive': True}\n2014-05-29 04:47:25,017 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}\n2014-05-29 04:47:25,019 - File['/etc/hadoop/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:25,027 - File['/etc/hadoop/conf/hadoop-env.sh'] {'content': Template('hadoop-env.sh.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:25,028 - File['/etc/hadoop/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:25,031 - File['/etc/hadoop/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:25,034 - File['/etc/hadoop/conf/health_check'] {'content': Template('health_check-v2.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:25,035 - File['/etc/hadoop/conf/log4j.properties'] {'content': '...', 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:25,040 - File['/etc/hadoop/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs'}\n2014-05-29 04:47:25,041 - XmlConfig['mapred-queue-acls.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:25,047 - Generating config: /etc/hadoop/conf/mapred-queue-acls.xml\n2014-05-29 04:47:25,047 - File['/etc/hadoop/conf/mapred-queue-acls.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:25,048 - Writing File['/etc/hadoop/conf/mapred-queue-acls.xml'] because contents don't match\n2014-05-29 04:47:25,049 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:25,053 - Generating config: /etc/hadoop/conf/hadoop-policy.xml\n2014-05-29 04:47:25,054 - File['/etc/hadoop/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:25,054 - Writing File['/etc/hadoop/conf/hadoop-policy.xml'] because contents don't match\n2014-05-29 04:47:25,055 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:25,058 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:47:25,058 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:25,059 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:47:25,060 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:25,064 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:47:25,064 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:25,065 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:47:25,065 - File['/etc/hadoop/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}\n2014-05-29 04:47:25,067 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:25,070 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:47:25,071 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:25,071 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:47:25,072 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:25,075 - Generating config: /etc/hadoop/conf/hdfs-site.xml\n2014-05-29 04:47:25,076 - File['/etc/hadoop/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None}\n2014-05-29 04:47:25,077 - Writing File['/etc/hadoop/conf/hdfs-site.xml'] because contents don't match\n2014-05-29 04:47:25,077 - File['/etc/hadoop/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}\n2014-05-29 04:47:25,078 - File['/etc/hadoop/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:47:25,078 - File['/etc/hadoop/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}\n2014-05-29 04:47:25,227 - HdfsDirectory['/app-logs'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'recursive_chmod': True, 'owner': 'yarn', 'group': 'hadoop', 'action': ['create_delayed'], 'mode': 0777}\n2014-05-29 04:47:25,228 - HdfsDirectory['/mapred'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'owner': 'mapred', 'action': ['create_delayed']}\n2014-05-29 04:47:25,228 - HdfsDirectory['/mapred/system'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'owner': 'hdfs', 'action': ['create_delayed']}\n2014-05-29 04:47:25,229 - HdfsDirectory['/mr-history/tmp'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'mode': 0777, 'owner': 'mapred', 'group': 'hadoop', 'action': ['create_delayed']}\n2014-05-29 04:47:25,229 - HdfsDirectory['/mr-history/done'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'mode': 01777, 'owner': 'mapred', 'group': 'hadoop', 'action': ['create_delayed']}\n2014-05-29 04:47:25,229 - HdfsDirectory['None'] {'security_enabled': False, 'keytab': [EMPTY], 'conf_dir': '/etc/hadoop/conf', 'hdfs_user': 'hdfs', 'kinit_path_local': '', 'action': ['create']}\n2014-05-29 04:47:25,232 - Execute['hadoop fs -mkdir `rpm -q hadoop | grep -q \"hadoop-1\" || echo \"-p\"` /app-logs /mapred /mapred/system /mr-history/tmp /mr-history/done && hadoop fs -chmod -R 777 /app-logs && hadoop fs -chmod  777 /mr-history/tmp && hadoop fs -chmod  1777 /mr-history/done && hadoop fs -chown  mapred /mapred && hadoop fs -chown  hdfs /mapred/system && hadoop fs -chown  yarn:hadoop /app-logs && hadoop fs -chown  mapred:hadoop /mr-history/tmp /mr-history/done'] {'not_if': \"su - hdfs -c 'hadoop fs -ls /app-logs /mapred /mapred/system /mr-history/tmp /mr-history/done'\", 'user': 'hdfs'}\n2014-05-29 04:47:30,381 - Skipping Execute['hadoop fs -mkdir `rpm -q hadoop | grep -q \"hadoop-1\" || echo \"-p\"` /app-logs /mapred /mapred/system /mr-history/tmp /mr-history/done && hadoop fs -chmod -R 777 /app-logs && hadoop fs -chmod  777 /mr-history/tmp && hadoop fs -chmod  1777 /mr-history/done && hadoop fs -chown  mapred /mapred && hadoop fs -chown  hdfs /mapred/system && hadoop fs -chown  yarn:hadoop /app-logs && hadoop fs -chown  mapred:hadoop /mr-history/tmp /mr-history/done'] due to not_if\n2014-05-29 04:47:30,383 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:47:30,385 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:47:30,385 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:47:30,387 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'recursive': True}\n2014-05-29 04:47:30,387 - Directory['/hadoop/yarn/local'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:47:30,387 - Directory['/hadoop/yarn/log'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:47:30,388 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'ignore_failures': True, 'recursive': True}\n2014-05-29 04:47:30,388 - XmlConfig['core-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:30,395 - Generating config: /etc/hadoop/conf/core-site.xml\n2014-05-29 04:47:30,395 - File['/etc/hadoop/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:30,396 - Writing File['/etc/hadoop/conf/core-site.xml'] because contents don't match\n2014-05-29 04:47:30,397 - XmlConfig['mapred-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:30,401 - Generating config: /etc/hadoop/conf/mapred-site.xml\n2014-05-29 04:47:30,401 - File['/etc/hadoop/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:30,402 - Writing File['/etc/hadoop/conf/mapred-site.xml'] because contents don't match\n2014-05-29 04:47:30,402 - Changing owner for /etc/hadoop/conf/mapred-site.xml from 1004 to yarn\n2014-05-29 04:47:30,404 - XmlConfig['yarn-site.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:30,407 - Generating config: /etc/hadoop/conf/yarn-site.xml\n2014-05-29 04:47:30,407 - File['/etc/hadoop/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:30,408 - Writing File['/etc/hadoop/conf/yarn-site.xml'] because contents don't match\n2014-05-29 04:47:30,408 - XmlConfig['capacity-scheduler.xml'] {'owner': 'yarn', 'group': 'hadoop', 'mode': 0644, 'conf_dir': '/etc/hadoop/conf', 'configurations': ...}\n2014-05-29 04:47:30,412 - Generating config: /etc/hadoop/conf/capacity-scheduler.xml\n2014-05-29 04:47:30,414 - File['/etc/hadoop/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644}\n2014-05-29 04:47:30,415 - Writing File['/etc/hadoop/conf/capacity-scheduler.xml'] because contents don't match\n2014-05-29 04:47:30,415 - Changing owner for /etc/hadoop/conf/capacity-scheduler.xml from 1003 to yarn\n2014-05-29 04:47:30,416 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}\n2014-05-29 04:47:30,418 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}\n2014-05-29 04:47:30,422 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}\n2014-05-29 04:47:30,427 - File['/etc/hadoop/conf/yarn-env.sh'] {'content': Template('yarn-env.sh.j2'), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}\n2014-05-29 04:47:30,428 - Execute['export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'] {'not_if': 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid` >/dev/null 2>&1', 'user': 'yarn'}\n2014-05-29 04:47:31,627 - Execute['ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid` >/dev/null 2>&1'] {'initial_wait': 5, 'not_if': 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid` >/dev/null 2>&1', 'user': 'yarn'}\n2014-05-29 04:47:36,662 - Skipping Execute['ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid` >/dev/null 2>&1'] due to not_if",
        "structured_out" : "{}"
      }
    }
  ]
}